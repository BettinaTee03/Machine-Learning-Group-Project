{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be building our model for the closed-world experiments to classify 95 monitored websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import psutil\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we will first import the dataframes into this notebook. Run either 1 of these blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using Google Colab, run this block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Use this with colab\n",
    "print(\"Loading datafile...\")\n",
    "with open('datasets/extracted_features.pkl', 'rb') as f:\n",
    "    extracted_df = pickle.load(f)\n",
    "print (\"Data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using local, run this block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datafile...\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "# 2 Use this for local (change the directory to where the extracted_features.pkl is stored on your local machine)\n",
    "# Load the pickle file\n",
    "print(\"Loading datafile...\")\n",
    "# change this directory to the directory where mon_standard.pkl is stored on your local machine\n",
    "file_path = r'C:\\EWHA\\Term 2\\Machine Learning\\pro\\neurotic_networkers\\extracted_features.pkl' # Jordans local path\n",
    "with open(file_path, 'rb') as f: # Path to extracted_features.pkl in Colab\n",
    "    extracted_df = pickle.load(f)\n",
    "print (\"Data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>incoming_packet_counts</th>\n",
       "      <th>outgoing_packet_counts</th>\n",
       "      <th>total_packet_counts</th>\n",
       "      <th>incoming_packet_fraction</th>\n",
       "      <th>outgoing_packet_fraction</th>\n",
       "      <th>std_outgoing_order</th>\n",
       "      <th>avg_outgoing_order</th>\n",
       "      <th>sum_concentration</th>\n",
       "      <th>avg_concentration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1300</td>\n",
       "      <td>121</td>\n",
       "      <td>1421</td>\n",
       "      <td>0.914849</td>\n",
       "      <td>0.085151</td>\n",
       "      <td>515.483953</td>\n",
       "      <td>773.322314</td>\n",
       "      <td>10.14</td>\n",
       "      <td>0.007136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>438</td>\n",
       "      <td>80</td>\n",
       "      <td>518</td>\n",
       "      <td>0.845560</td>\n",
       "      <td>0.154440</td>\n",
       "      <td>139.231951</td>\n",
       "      <td>226.162500</td>\n",
       "      <td>10.16</td>\n",
       "      <td>0.019614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1240</td>\n",
       "      <td>118</td>\n",
       "      <td>1358</td>\n",
       "      <td>0.913108</td>\n",
       "      <td>0.086892</td>\n",
       "      <td>472.735508</td>\n",
       "      <td>786.110169</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.008181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1324</td>\n",
       "      <td>122</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.915629</td>\n",
       "      <td>0.084371</td>\n",
       "      <td>513.916038</td>\n",
       "      <td>820.139344</td>\n",
       "      <td>13.36</td>\n",
       "      <td>0.009239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1291</td>\n",
       "      <td>115</td>\n",
       "      <td>1406</td>\n",
       "      <td>0.918208</td>\n",
       "      <td>0.081792</td>\n",
       "      <td>503.993490</td>\n",
       "      <td>789.608696</td>\n",
       "      <td>10.64</td>\n",
       "      <td>0.007568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28995</th>\n",
       "      <td>-1</td>\n",
       "      <td>4180</td>\n",
       "      <td>413</td>\n",
       "      <td>4593</td>\n",
       "      <td>0.910081</td>\n",
       "      <td>0.089919</td>\n",
       "      <td>1173.380403</td>\n",
       "      <td>2549.414044</td>\n",
       "      <td>32.09</td>\n",
       "      <td>0.006987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28996</th>\n",
       "      <td>-1</td>\n",
       "      <td>4663</td>\n",
       "      <td>447</td>\n",
       "      <td>5110</td>\n",
       "      <td>0.912524</td>\n",
       "      <td>0.087476</td>\n",
       "      <td>1621.869237</td>\n",
       "      <td>3062.015660</td>\n",
       "      <td>38.62</td>\n",
       "      <td>0.007558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28997</th>\n",
       "      <td>-1</td>\n",
       "      <td>302</td>\n",
       "      <td>59</td>\n",
       "      <td>361</td>\n",
       "      <td>0.836565</td>\n",
       "      <td>0.163435</td>\n",
       "      <td>118.245320</td>\n",
       "      <td>179.101695</td>\n",
       "      <td>34.93</td>\n",
       "      <td>0.096759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28998</th>\n",
       "      <td>-1</td>\n",
       "      <td>413</td>\n",
       "      <td>96</td>\n",
       "      <td>509</td>\n",
       "      <td>0.811395</td>\n",
       "      <td>0.188605</td>\n",
       "      <td>166.667122</td>\n",
       "      <td>309.197917</td>\n",
       "      <td>11.84</td>\n",
       "      <td>0.023261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28999</th>\n",
       "      <td>-1</td>\n",
       "      <td>9668</td>\n",
       "      <td>322</td>\n",
       "      <td>9990</td>\n",
       "      <td>0.967768</td>\n",
       "      <td>0.032232</td>\n",
       "      <td>3076.060409</td>\n",
       "      <td>4627.602484</td>\n",
       "      <td>9.62</td>\n",
       "      <td>0.000963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  incoming_packet_counts  outgoing_packet_counts  \\\n",
       "0          0                    1300                     121   \n",
       "1          0                     438                      80   \n",
       "2          0                    1240                     118   \n",
       "3          0                    1324                     122   \n",
       "4          0                    1291                     115   \n",
       "...      ...                     ...                     ...   \n",
       "28995     -1                    4180                     413   \n",
       "28996     -1                    4663                     447   \n",
       "28997     -1                     302                      59   \n",
       "28998     -1                     413                      96   \n",
       "28999     -1                    9668                     322   \n",
       "\n",
       "       total_packet_counts  incoming_packet_fraction  \\\n",
       "0                     1421                  0.914849   \n",
       "1                      518                  0.845560   \n",
       "2                     1358                  0.913108   \n",
       "3                     1446                  0.915629   \n",
       "4                     1406                  0.918208   \n",
       "...                    ...                       ...   \n",
       "28995                 4593                  0.910081   \n",
       "28996                 5110                  0.912524   \n",
       "28997                  361                  0.836565   \n",
       "28998                  509                  0.811395   \n",
       "28999                 9990                  0.967768   \n",
       "\n",
       "       outgoing_packet_fraction  std_outgoing_order  avg_outgoing_order  \\\n",
       "0                      0.085151          515.483953          773.322314   \n",
       "1                      0.154440          139.231951          226.162500   \n",
       "2                      0.086892          472.735508          786.110169   \n",
       "3                      0.084371          513.916038          820.139344   \n",
       "4                      0.081792          503.993490          789.608696   \n",
       "...                         ...                 ...                 ...   \n",
       "28995                  0.089919         1173.380403         2549.414044   \n",
       "28996                  0.087476         1621.869237         3062.015660   \n",
       "28997                  0.163435          118.245320          179.101695   \n",
       "28998                  0.188605          166.667122          309.197917   \n",
       "28999                  0.032232         3076.060409         4627.602484   \n",
       "\n",
       "       sum_concentration  avg_concentration  \n",
       "0                  10.14           0.007136  \n",
       "1                  10.16           0.019614  \n",
       "2                  11.11           0.008181  \n",
       "3                  13.36           0.009239  \n",
       "4                  10.64           0.007568  \n",
       "...                  ...                ...  \n",
       "28995              32.09           0.006987  \n",
       "28996              38.62           0.007558  \n",
       "28997              34.93           0.096759  \n",
       "28998              11.84           0.023261  \n",
       "28999               9.62           0.000963  \n",
       "\n",
       "[29000 rows x 10 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, since we will only be dealing with the closed world experiments, we will first extract the relevant data from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_world_df = extracted_df[extracted_df['label'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>incoming_packet_counts</th>\n",
       "      <th>outgoing_packet_counts</th>\n",
       "      <th>total_packet_counts</th>\n",
       "      <th>incoming_packet_fraction</th>\n",
       "      <th>outgoing_packet_fraction</th>\n",
       "      <th>std_outgoing_order</th>\n",
       "      <th>avg_outgoing_order</th>\n",
       "      <th>sum_concentration</th>\n",
       "      <th>avg_concentration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1300</td>\n",
       "      <td>121</td>\n",
       "      <td>1421</td>\n",
       "      <td>0.914849</td>\n",
       "      <td>0.085151</td>\n",
       "      <td>515.483953</td>\n",
       "      <td>773.322314</td>\n",
       "      <td>10.14</td>\n",
       "      <td>0.007136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>438</td>\n",
       "      <td>80</td>\n",
       "      <td>518</td>\n",
       "      <td>0.845560</td>\n",
       "      <td>0.154440</td>\n",
       "      <td>139.231951</td>\n",
       "      <td>226.162500</td>\n",
       "      <td>10.16</td>\n",
       "      <td>0.019614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1240</td>\n",
       "      <td>118</td>\n",
       "      <td>1358</td>\n",
       "      <td>0.913108</td>\n",
       "      <td>0.086892</td>\n",
       "      <td>472.735508</td>\n",
       "      <td>786.110169</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.008181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1324</td>\n",
       "      <td>122</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.915629</td>\n",
       "      <td>0.084371</td>\n",
       "      <td>513.916038</td>\n",
       "      <td>820.139344</td>\n",
       "      <td>13.36</td>\n",
       "      <td>0.009239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1291</td>\n",
       "      <td>115</td>\n",
       "      <td>1406</td>\n",
       "      <td>0.918208</td>\n",
       "      <td>0.081792</td>\n",
       "      <td>503.993490</td>\n",
       "      <td>789.608696</td>\n",
       "      <td>10.64</td>\n",
       "      <td>0.007568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18995</th>\n",
       "      <td>94</td>\n",
       "      <td>8815</td>\n",
       "      <td>619</td>\n",
       "      <td>9434</td>\n",
       "      <td>0.934386</td>\n",
       "      <td>0.065614</td>\n",
       "      <td>3053.116218</td>\n",
       "      <td>4844.586430</td>\n",
       "      <td>43.91</td>\n",
       "      <td>0.004654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18996</th>\n",
       "      <td>94</td>\n",
       "      <td>9404</td>\n",
       "      <td>552</td>\n",
       "      <td>9956</td>\n",
       "      <td>0.944556</td>\n",
       "      <td>0.055444</td>\n",
       "      <td>3010.091146</td>\n",
       "      <td>4541.974638</td>\n",
       "      <td>15.60</td>\n",
       "      <td>0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18997</th>\n",
       "      <td>94</td>\n",
       "      <td>9373</td>\n",
       "      <td>579</td>\n",
       "      <td>9952</td>\n",
       "      <td>0.941821</td>\n",
       "      <td>0.058179</td>\n",
       "      <td>3102.381602</td>\n",
       "      <td>4766.072539</td>\n",
       "      <td>14.93</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18998</th>\n",
       "      <td>94</td>\n",
       "      <td>9236</td>\n",
       "      <td>690</td>\n",
       "      <td>9926</td>\n",
       "      <td>0.930486</td>\n",
       "      <td>0.069514</td>\n",
       "      <td>3116.574388</td>\n",
       "      <td>5278.146377</td>\n",
       "      <td>19.91</td>\n",
       "      <td>0.002006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18999</th>\n",
       "      <td>94</td>\n",
       "      <td>9168</td>\n",
       "      <td>757</td>\n",
       "      <td>9925</td>\n",
       "      <td>0.923728</td>\n",
       "      <td>0.076272</td>\n",
       "      <td>3269.954300</td>\n",
       "      <td>5452.516513</td>\n",
       "      <td>13.76</td>\n",
       "      <td>0.001386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  incoming_packet_counts  outgoing_packet_counts  \\\n",
       "0          0                    1300                     121   \n",
       "1          0                     438                      80   \n",
       "2          0                    1240                     118   \n",
       "3          0                    1324                     122   \n",
       "4          0                    1291                     115   \n",
       "...      ...                     ...                     ...   \n",
       "18995     94                    8815                     619   \n",
       "18996     94                    9404                     552   \n",
       "18997     94                    9373                     579   \n",
       "18998     94                    9236                     690   \n",
       "18999     94                    9168                     757   \n",
       "\n",
       "       total_packet_counts  incoming_packet_fraction  \\\n",
       "0                     1421                  0.914849   \n",
       "1                      518                  0.845560   \n",
       "2                     1358                  0.913108   \n",
       "3                     1446                  0.915629   \n",
       "4                     1406                  0.918208   \n",
       "...                    ...                       ...   \n",
       "18995                 9434                  0.934386   \n",
       "18996                 9956                  0.944556   \n",
       "18997                 9952                  0.941821   \n",
       "18998                 9926                  0.930486   \n",
       "18999                 9925                  0.923728   \n",
       "\n",
       "       outgoing_packet_fraction  std_outgoing_order  avg_outgoing_order  \\\n",
       "0                      0.085151          515.483953          773.322314   \n",
       "1                      0.154440          139.231951          226.162500   \n",
       "2                      0.086892          472.735508          786.110169   \n",
       "3                      0.084371          513.916038          820.139344   \n",
       "4                      0.081792          503.993490          789.608696   \n",
       "...                         ...                 ...                 ...   \n",
       "18995                  0.065614         3053.116218         4844.586430   \n",
       "18996                  0.055444         3010.091146         4541.974638   \n",
       "18997                  0.058179         3102.381602         4766.072539   \n",
       "18998                  0.069514         3116.574388         5278.146377   \n",
       "18999                  0.076272         3269.954300         5452.516513   \n",
       "\n",
       "       sum_concentration  avg_concentration  \n",
       "0                  10.14           0.007136  \n",
       "1                  10.16           0.019614  \n",
       "2                  11.11           0.008181  \n",
       "3                  13.36           0.009239  \n",
       "4                  10.64           0.007568  \n",
       "...                  ...                ...  \n",
       "18995              43.91           0.004654  \n",
       "18996              15.60           0.001567  \n",
       "18997              14.93           0.001500  \n",
       "18998              19.91           0.002006  \n",
       "18999              13.76           0.001386  \n",
       "\n",
       "[19000 rows x 10 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closed_world_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we separate the features and the target. Target will be label which represents the label of the monitored websites. Features will be the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_initial = closed_world_df.drop(columns=['label'])\n",
    "y_initial = closed_world_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing Model with all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we construct a model using all of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_initial_train, X_initial_test, y_initial_train, y_initial_test = train_test_split(\n",
    "    X_initial, y_initial, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 710.6929603735165\n",
      "R^2 Score: 0.029731476003219015\n",
      "Time to run: 0.00 seconds\n",
      "Memory used: 1170.86 MB\n",
      "Model R^2 Accuracy: 2.97%\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Model with scaled data\n",
    "\n",
    "# Scale the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_X_initial_train = scaler.fit_transform(X_initial_train)\n",
    "scaled_X_initial_test = scaler.transform(X_initial_test)\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "lr_model.fit(scaled_X_initial_train, y_initial_train)\n",
    "\n",
    "# Calculate RAM usage\n",
    "process = psutil.Process(os.getpid())\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lr_model.predict(scaled_X_initial_test)\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print regression metrics\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_initial_test, y_pred))\n",
    "print(\"R^2 Score:\", r2_score(y_initial_test, y_pred))\n",
    "print(\"Time to run: {:.2f} seconds\".format(end_time - start_time))\n",
    "print(\"Memory used: {:.2f} MB\".format(process.memory_info().rss / 1024 ** 2))\n",
    "print(\"Model R^2 Accuracy: {:.2f}%\".format(r2_score(y_initial_test, y_pred) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run: 9.64 seconds\n",
      "Memory used: 1181.73 MB\n",
      "Model Accuracy: 35.95%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.10      0.17        42\n",
      "           1       1.00      0.00      0.00        42\n",
      "           2       0.19      0.57      0.29        35\n",
      "           3       0.25      0.14      0.18        29\n",
      "           4       0.07      0.03      0.04        39\n",
      "           5       0.58      0.24      0.34        45\n",
      "           6       0.32      0.82      0.46        44\n",
      "           7       0.11      0.19      0.14        36\n",
      "           8       0.38      0.18      0.24        34\n",
      "           9       0.18      0.42      0.25        31\n",
      "          10       0.33      0.04      0.08        47\n",
      "          11       0.48      0.40      0.44        35\n",
      "          12       0.66      0.64      0.65        42\n",
      "          13       1.00      0.00      0.00        40\n",
      "          14       0.46      0.17      0.24        36\n",
      "          15       0.18      0.37      0.24        35\n",
      "          16       0.96      0.56      0.71        43\n",
      "          17       0.10      0.11      0.10        47\n",
      "          18       0.26      0.16      0.20        37\n",
      "          19       0.05      0.14      0.07        37\n",
      "          20       0.60      0.93      0.73        44\n",
      "          21       0.60      0.37      0.45        41\n",
      "          22       0.30      0.30      0.30        40\n",
      "          23       0.29      0.46      0.36        35\n",
      "          24       0.09      0.11      0.10        46\n",
      "          25       1.00      0.00      0.00        36\n",
      "          26       0.42      0.59      0.49        37\n",
      "          27       0.67      0.27      0.38        45\n",
      "          28       0.17      0.03      0.05        36\n",
      "          29       0.30      0.40      0.34        47\n",
      "          30       0.60      0.65      0.62        46\n",
      "          31       0.29      0.05      0.09        37\n",
      "          32       0.35      0.29      0.32        38\n",
      "          33       0.55      0.59      0.57        37\n",
      "          34       0.33      0.12      0.18        41\n",
      "          35       0.45      0.71      0.55        38\n",
      "          36       0.30      0.66      0.41        35\n",
      "          37       1.00      0.00      0.00        53\n",
      "          38       0.29      0.47      0.36        53\n",
      "          39       0.77      0.43      0.56        46\n",
      "          40       0.04      0.02      0.03        51\n",
      "          41       0.39      0.53      0.45        43\n",
      "          42       0.53      0.23      0.32        39\n",
      "          43       0.55      0.41      0.47        41\n",
      "          44       0.66      0.95      0.78        44\n",
      "          45       0.23      0.54      0.32        35\n",
      "          46       0.00      0.00      0.00        35\n",
      "          47       0.20      0.03      0.05        39\n",
      "          48       0.27      0.57      0.37        37\n",
      "          49       0.41      0.28      0.33        43\n",
      "          50       0.44      0.56      0.49        32\n",
      "          51       0.42      0.13      0.20        38\n",
      "          52       0.56      0.20      0.30        49\n",
      "          53       0.18      0.19      0.19        31\n",
      "          54       1.00      0.00      0.00        47\n",
      "          55       0.34      0.27      0.30        41\n",
      "          56       0.66      0.45      0.53        47\n",
      "          57       0.59      0.28      0.38        36\n",
      "          58       0.38      0.80      0.51        35\n",
      "          59       0.37      0.54      0.44        39\n",
      "          60       0.43      0.50      0.46        40\n",
      "          61       0.35      0.36      0.35        56\n",
      "          62       0.41      0.37      0.39        57\n",
      "          63       0.20      0.30      0.24        27\n",
      "          64       0.40      0.36      0.38        39\n",
      "          65       0.19      0.51      0.28        35\n",
      "          66       0.45      0.78      0.57        46\n",
      "          67       0.43      0.35      0.39        37\n",
      "          68       0.58      0.23      0.33        48\n",
      "          69       0.25      0.14      0.18        43\n",
      "          70       0.49      0.85      0.62        34\n",
      "          71       0.00      0.00      0.00        36\n",
      "          72       0.44      0.10      0.17        39\n",
      "          73       0.43      0.98      0.59        41\n",
      "          74       0.37      0.30      0.33        53\n",
      "          75       0.57      0.81      0.67        37\n",
      "          76       0.59      0.77      0.67        44\n",
      "          77       0.00      0.00      0.00        30\n",
      "          78       0.22      0.19      0.21        36\n",
      "          79       0.30      0.63      0.40        30\n",
      "          80       0.30      0.78      0.43        40\n",
      "          81       1.00      0.00      0.00        45\n",
      "          82       0.90      0.40      0.55        45\n",
      "          83       0.04      0.06      0.05        31\n",
      "          84       0.43      0.55      0.48        40\n",
      "          85       0.78      0.73      0.75        44\n",
      "          86       0.62      0.84      0.71        37\n",
      "          87       0.25      0.37      0.30        35\n",
      "          88       0.26      0.32      0.29        37\n",
      "          89       0.29      0.26      0.27        38\n",
      "          90       0.30      0.31      0.30        36\n",
      "          91       0.14      0.10      0.12        39\n",
      "          92       1.00      0.00      0.00        35\n",
      "          93       0.56      0.62      0.59        39\n",
      "          94       0.28      0.55      0.37        42\n",
      "\n",
      "    accuracy                           0.36      3800\n",
      "   macro avg       0.42      0.36      0.32      3800\n",
      "weighted avg       0.44      0.36      0.33      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM Model with scaled data\n",
    "\n",
    "# Scale the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_X_initial_train = scaler.fit_transform(X_initial_train)\n",
    "scaled_X_initial_test = scaler.transform(X_initial_test)\n",
    "\n",
    "# Initialize the SVC model\n",
    "SVM_model = SVC()\n",
    "\n",
    "# Train the model\n",
    "SVM_model.fit(scaled_X_initial_train, y_initial_train)\n",
    "\n",
    "# Calculate RAM usage\n",
    "process = psutil.Process(os.getpid())\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = SVM_model.predict(scaled_X_initial_test)\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Time to run: {:.2f} seconds\".format(end_time - start_time))\n",
    "print(\"Memory used: {:.2f} MB\".format(process.memory_info().rss / 1024 ** 2))\n",
    "print(\"Model Accuracy: {:.2f}%\".format(SVM_model.score(scaled_X_initial_test, y_initial_test) * 100))\n",
    "print(classification_report(y_initial_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=100, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=100, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=100, random_state=42)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "clf_all_features = RandomForestClassifier(n_estimators=100, criterion=\"entropy\", max_depth=100, min_samples_split=2, max_features=\"sqrt\", random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf_all_features.fit(X_initial_train, y_initial_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a process object to track current process\n",
    "process = psutil.Process(os.getpid())\n",
    "# tracking start memory\n",
    "memory_before = process.memory_info().rss / (1024 * 1024)\n",
    "# tracking start time\n",
    "start_time = time.time()\n",
    "# Make predictions on the train set\n",
    "y_initial_train_pred = clf_all_features.predict(X_initial_train)\n",
    "# tracking end time\n",
    "end_time = time.time()\n",
    "# tracking end memory\n",
    "memory_after = process.memory_info().rss / (1024 * 1024)\n",
    "\n",
    "time_taken_all_features_train = end_time - start_time\n",
    "memory_used_all_features_train = memory_after - memory_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 0.01171875 MB\n",
      "Time taken to predict: 0.6969203948974609 seconds\n",
      "Model Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       158\n",
      "           1       1.00      1.00      1.00       158\n",
      "           2       1.00      1.00      1.00       165\n",
      "           3       1.00      1.00      1.00       171\n",
      "           4       1.00      1.00      1.00       161\n",
      "           5       1.00      1.00      1.00       155\n",
      "           6       1.00      1.00      1.00       156\n",
      "           7       1.00      1.00      1.00       164\n",
      "           8       1.00      1.00      1.00       166\n",
      "           9       1.00      1.00      1.00       169\n",
      "          10       1.00      1.00      1.00       153\n",
      "          11       1.00      1.00      1.00       165\n",
      "          12       1.00      1.00      1.00       158\n",
      "          13       1.00      1.00      1.00       160\n",
      "          14       1.00      1.00      1.00       164\n",
      "          15       1.00      1.00      1.00       165\n",
      "          16       1.00      1.00      1.00       157\n",
      "          17       1.00      1.00      1.00       153\n",
      "          18       1.00      1.00      1.00       163\n",
      "          19       1.00      1.00      1.00       163\n",
      "          20       1.00      1.00      1.00       156\n",
      "          21       1.00      1.00      1.00       159\n",
      "          22       1.00      1.00      1.00       160\n",
      "          23       1.00      1.00      1.00       165\n",
      "          24       1.00      1.00      1.00       154\n",
      "          25       1.00      1.00      1.00       164\n",
      "          26       1.00      1.00      1.00       163\n",
      "          27       1.00      1.00      1.00       155\n",
      "          28       1.00      1.00      1.00       164\n",
      "          29       1.00      1.00      1.00       153\n",
      "          30       1.00      1.00      1.00       154\n",
      "          31       1.00      1.00      1.00       163\n",
      "          32       1.00      1.00      1.00       162\n",
      "          33       1.00      1.00      1.00       163\n",
      "          34       1.00      1.00      1.00       159\n",
      "          35       1.00      1.00      1.00       162\n",
      "          36       1.00      1.00      1.00       165\n",
      "          37       1.00      1.00      1.00       147\n",
      "          38       1.00      1.00      1.00       147\n",
      "          39       1.00      1.00      1.00       154\n",
      "          40       1.00      1.00      1.00       149\n",
      "          41       1.00      1.00      1.00       157\n",
      "          42       1.00      1.00      1.00       161\n",
      "          43       1.00      1.00      1.00       159\n",
      "          44       1.00      1.00      1.00       156\n",
      "          45       1.00      1.00      1.00       165\n",
      "          46       1.00      1.00      1.00       165\n",
      "          47       1.00      1.00      1.00       161\n",
      "          48       1.00      1.00      1.00       163\n",
      "          49       1.00      1.00      1.00       157\n",
      "          50       1.00      1.00      1.00       168\n",
      "          51       1.00      1.00      1.00       162\n",
      "          52       1.00      1.00      1.00       151\n",
      "          53       1.00      1.00      1.00       169\n",
      "          54       1.00      1.00      1.00       153\n",
      "          55       1.00      1.00      1.00       159\n",
      "          56       1.00      1.00      1.00       153\n",
      "          57       1.00      1.00      1.00       164\n",
      "          58       1.00      1.00      1.00       165\n",
      "          59       1.00      1.00      1.00       161\n",
      "          60       1.00      1.00      1.00       160\n",
      "          61       1.00      1.00      1.00       144\n",
      "          62       1.00      1.00      1.00       143\n",
      "          63       1.00      1.00      1.00       173\n",
      "          64       1.00      1.00      1.00       161\n",
      "          65       1.00      1.00      1.00       165\n",
      "          66       1.00      1.00      1.00       154\n",
      "          67       1.00      1.00      1.00       163\n",
      "          68       1.00      1.00      1.00       152\n",
      "          69       1.00      1.00      1.00       157\n",
      "          70       1.00      1.00      1.00       166\n",
      "          71       1.00      1.00      1.00       164\n",
      "          72       1.00      1.00      1.00       161\n",
      "          73       1.00      1.00      1.00       159\n",
      "          74       1.00      1.00      1.00       147\n",
      "          75       1.00      1.00      1.00       163\n",
      "          76       1.00      1.00      1.00       156\n",
      "          77       1.00      1.00      1.00       170\n",
      "          78       1.00      1.00      1.00       164\n",
      "          79       1.00      1.00      1.00       170\n",
      "          80       1.00      1.00      1.00       160\n",
      "          81       1.00      1.00      1.00       155\n",
      "          82       1.00      1.00      1.00       155\n",
      "          83       1.00      1.00      1.00       169\n",
      "          84       1.00      1.00      1.00       160\n",
      "          85       1.00      1.00      1.00       156\n",
      "          86       1.00      1.00      1.00       163\n",
      "          87       1.00      1.00      1.00       165\n",
      "          88       1.00      1.00      1.00       163\n",
      "          89       1.00      1.00      1.00       162\n",
      "          90       1.00      1.00      1.00       164\n",
      "          91       1.00      1.00      1.00       161\n",
      "          92       1.00      1.00      1.00       165\n",
      "          93       1.00      1.00      1.00       161\n",
      "          94       1.00      1.00      1.00       158\n",
      "\n",
      "    accuracy                           1.00     15200\n",
      "   macro avg       1.00      1.00      1.00     15200\n",
      "weighted avg       1.00      1.00      1.00     15200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy and other metrics\n",
    "print(\"Memory used:\", memory_used_all_features_train, \"MB\")\n",
    "print(\"Time taken to predict:\", time_taken_all_features_train, \"seconds\")\n",
    "print(\"Model Accuracy:\", accuracy_score(y_initial_train, y_initial_train_pred))\n",
    "print(classification_report(y_initial_train, y_initial_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a process object to track current process\n",
    "process = psutil.Process(os.getpid())\n",
    "# tracking start memory\n",
    "memory_before = process.memory_info().rss / (1024 * 1024)\n",
    "# tracking start time\n",
    "start_time = time.time()\n",
    "# Make predictions on the test set\n",
    "y_initial_test_pred = clf_all_features.predict(X_initial_test)\n",
    "# tracking end time\n",
    "end_time = time.time()\n",
    "# tracking end memory\n",
    "memory_after = process.memory_info().rss / (1024 * 1024)\n",
    "\n",
    "time_taken_all_features_test = end_time - start_time\n",
    "memory_used_all_features_test = memory_after - memory_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 0.0234375 MB\n",
      "Time taken to predict: 0.1804347038269043 seconds\n",
      "Model Accuracy: 0.7307894736842105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.71      0.74        42\n",
      "           1       0.56      0.36      0.43        42\n",
      "           2       0.76      0.89      0.82        35\n",
      "           3       0.71      0.86      0.78        29\n",
      "           4       0.71      0.87      0.78        39\n",
      "           5       0.88      0.93      0.90        45\n",
      "           6       0.78      0.86      0.82        44\n",
      "           7       0.69      0.67      0.68        36\n",
      "           8       0.65      0.76      0.70        34\n",
      "           9       0.54      0.71      0.61        31\n",
      "          10       0.87      0.70      0.78        47\n",
      "          11       0.67      0.74      0.70        35\n",
      "          12       0.88      0.86      0.87        42\n",
      "          13       0.50      0.53      0.51        40\n",
      "          14       0.66      0.53      0.58        36\n",
      "          15       0.76      0.71      0.74        35\n",
      "          16       0.85      0.65      0.74        43\n",
      "          17       0.65      0.64      0.65        47\n",
      "          18       0.79      0.89      0.84        37\n",
      "          19       0.68      0.68      0.68        37\n",
      "          20       0.82      0.91      0.86        44\n",
      "          21       0.68      0.51      0.58        41\n",
      "          22       0.75      0.68      0.71        40\n",
      "          23       0.90      0.74      0.81        35\n",
      "          24       0.39      0.33      0.36        46\n",
      "          25       0.72      0.64      0.68        36\n",
      "          26       0.75      0.97      0.85        37\n",
      "          27       0.76      0.64      0.70        45\n",
      "          28       0.88      0.83      0.86        36\n",
      "          29       0.57      0.72      0.64        47\n",
      "          30       0.68      0.85      0.76        46\n",
      "          31       0.77      0.81      0.79        37\n",
      "          32       0.65      0.58      0.61        38\n",
      "          33       0.65      0.86      0.74        37\n",
      "          34       0.75      0.66      0.70        41\n",
      "          35       0.79      0.87      0.82        38\n",
      "          36       0.76      0.83      0.79        35\n",
      "          37       0.84      0.60      0.70        53\n",
      "          38       0.70      0.79      0.74        53\n",
      "          39       0.91      0.70      0.79        46\n",
      "          40       0.77      0.67      0.72        51\n",
      "          41       0.78      0.84      0.81        43\n",
      "          42       0.68      0.54      0.60        39\n",
      "          43       0.77      0.90      0.83        41\n",
      "          44       0.98      0.98      0.98        44\n",
      "          45       0.49      0.54      0.51        35\n",
      "          46       0.83      0.69      0.75        35\n",
      "          47       0.81      0.56      0.67        39\n",
      "          48       0.67      0.76      0.71        37\n",
      "          49       0.82      0.74      0.78        43\n",
      "          50       0.59      0.81      0.68        32\n",
      "          51       0.50      0.47      0.49        38\n",
      "          52       0.80      0.80      0.80        49\n",
      "          53       0.60      0.68      0.64        31\n",
      "          54       0.95      0.74      0.83        47\n",
      "          55       0.60      0.61      0.60        41\n",
      "          56       0.93      0.89      0.91        47\n",
      "          57       0.80      0.78      0.79        36\n",
      "          58       0.94      0.86      0.90        35\n",
      "          59       0.80      0.85      0.82        39\n",
      "          60       0.74      0.88      0.80        40\n",
      "          61       0.82      0.71      0.76        56\n",
      "          62       0.83      0.77      0.80        57\n",
      "          63       0.59      0.70      0.64        27\n",
      "          64       0.56      0.69      0.62        39\n",
      "          65       0.57      0.66      0.61        35\n",
      "          66       0.72      0.85      0.78        46\n",
      "          67       0.68      0.86      0.76        37\n",
      "          68       0.75      0.56      0.64        48\n",
      "          69       0.66      0.63      0.64        43\n",
      "          70       0.91      0.94      0.93        34\n",
      "          71       0.67      0.81      0.73        36\n",
      "          72       0.76      0.72      0.74        39\n",
      "          73       0.90      0.93      0.92        41\n",
      "          74       0.76      0.55      0.64        53\n",
      "          75       0.97      0.92      0.94        37\n",
      "          76       0.98      0.93      0.95        44\n",
      "          77       0.50      0.53      0.52        30\n",
      "          78       0.52      0.42      0.46        36\n",
      "          79       0.56      0.73      0.64        30\n",
      "          80       0.89      0.85      0.87        40\n",
      "          81       0.75      0.73      0.74        45\n",
      "          82       0.66      0.47      0.55        45\n",
      "          83       0.74      0.94      0.83        31\n",
      "          84       0.71      0.72      0.72        40\n",
      "          85       0.89      0.77      0.83        44\n",
      "          86       0.92      0.97      0.95        37\n",
      "          87       0.81      0.74      0.78        35\n",
      "          88       0.67      0.70      0.68        37\n",
      "          89       0.60      0.63      0.62        38\n",
      "          90       0.63      0.67      0.65        36\n",
      "          91       0.62      0.77      0.69        39\n",
      "          92       0.56      0.63      0.59        35\n",
      "          93       0.78      0.92      0.85        39\n",
      "          94       0.57      0.50      0.53        42\n",
      "\n",
      "    accuracy                           0.73      3800\n",
      "   macro avg       0.73      0.73      0.73      3800\n",
      "weighted avg       0.74      0.73      0.73      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy and other metrics\n",
    "print(\"Memory used:\", memory_used_all_features_test, \"MB\")\n",
    "print(\"Time taken to predict:\", time_taken_all_features_test, \"seconds\")\n",
    "print(\"Model Accuracy:\", accuracy_score(y_initial_test, y_initial_test_pred))\n",
    "print(classification_report(y_initial_test, y_initial_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.DataFrame(X_initial_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incoming_packet_counts</th>\n",
       "      <th>outgoing_packet_counts</th>\n",
       "      <th>total_packet_counts</th>\n",
       "      <th>incoming_packet_fraction</th>\n",
       "      <th>outgoing_packet_fraction</th>\n",
       "      <th>std_outgoing_order</th>\n",
       "      <th>avg_outgoing_order</th>\n",
       "      <th>sum_concentration</th>\n",
       "      <th>avg_concentration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6787</th>\n",
       "      <td>5595</td>\n",
       "      <td>798</td>\n",
       "      <td>6393</td>\n",
       "      <td>0.875176</td>\n",
       "      <td>0.124824</td>\n",
       "      <td>1667.233686</td>\n",
       "      <td>3442.906015</td>\n",
       "      <td>49.43</td>\n",
       "      <td>0.007732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>9586</td>\n",
       "      <td>392</td>\n",
       "      <td>9978</td>\n",
       "      <td>0.960714</td>\n",
       "      <td>0.039286</td>\n",
       "      <td>3032.469878</td>\n",
       "      <td>4233.829082</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.002004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11219</th>\n",
       "      <td>3327</td>\n",
       "      <td>156</td>\n",
       "      <td>3483</td>\n",
       "      <td>0.955211</td>\n",
       "      <td>0.044789</td>\n",
       "      <td>1080.035278</td>\n",
       "      <td>1165.185897</td>\n",
       "      <td>12.92</td>\n",
       "      <td>0.003709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>1744</td>\n",
       "      <td>80</td>\n",
       "      <td>1824</td>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>585.855395</td>\n",
       "      <td>675.262500</td>\n",
       "      <td>5.35</td>\n",
       "      <td>0.002933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>9150</td>\n",
       "      <td>786</td>\n",
       "      <td>9936</td>\n",
       "      <td>0.920894</td>\n",
       "      <td>0.079106</td>\n",
       "      <td>3260.813245</td>\n",
       "      <td>5420.637405</td>\n",
       "      <td>21.67</td>\n",
       "      <td>0.002181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       incoming_packet_counts  outgoing_packet_counts  total_packet_counts  \\\n",
       "6787                     5595                     798                 6393   \n",
       "6097                     9586                     392                 9978   \n",
       "11219                    3327                     156                 3483   \n",
       "2512                     1744                      80                 1824   \n",
       "4279                     9150                     786                 9936   \n",
       "\n",
       "       incoming_packet_fraction  outgoing_packet_fraction  std_outgoing_order  \\\n",
       "6787                   0.875176                  0.124824         1667.233686   \n",
       "6097                   0.960714                  0.039286         3032.469878   \n",
       "11219                  0.955211                  0.044789         1080.035278   \n",
       "2512                   0.956140                  0.043860          585.855395   \n",
       "4279                   0.920894                  0.079106         3260.813245   \n",
       "\n",
       "       avg_outgoing_order  sum_concentration  avg_concentration  \n",
       "6787          3442.906015              49.43           0.007732  \n",
       "6097          4233.829082              20.00           0.002004  \n",
       "11219         1165.185897              12.92           0.003709  \n",
       "2512           675.262500               5.35           0.002933  \n",
       "4279          5420.637405              21.67           0.002181  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using entropy\n",
    "model_1= RandomForestClassifier(n_estimators=100, criterion=\"entropy\", max_depth=100, min_samples_split=2, max_features=\"sqrt\", random_state=42)\n",
    "model_1.fit(X_initial_train, y_initial_train)\n",
    "feature_imp_1 = pd.Series(model_1.feature_importances_, index=df_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using gini\n",
    "model_2= RandomForestClassifier(n_estimators=100, criterion=\"gini\", max_depth=100, min_samples_split=2, max_features=\"sqrt\", random_state=42)\n",
    "model_2.fit(X_initial_train, y_initial_train)\n",
    "feature_imp_2 = pd.Series(model_2.feature_importances_, index=df_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_names = df_X.columns\n",
    "entropy_values = feature_imp_1.values\n",
    "gini_values = feature_imp_2.values\n",
    "\n",
    "bar_width = 0.4 \n",
    "y_positions = range(len(feature_names)) \n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "#plotting entropy importance\n",
    "plt.barh(\n",
    "    [y - bar_width / 2 for y in y_positions],\n",
    "    entropy_values,\n",
    "    bar_width,\n",
    "    label='Entropy',\n",
    "    color='blue',\n",
    ")\n",
    "\n",
    "# plotting gini improtance\n",
    "plt.barh(\n",
    "    [y + bar_width / 2 for y in y_positions],\n",
    "    gini_values,\n",
    "    bar_width,\n",
    "    label='Gini',\n",
    "    color='orange',\n",
    ")\n",
    "\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.yticks(y_positions, feature_names) \n",
    "plt.title('Visualisation of Feature Importance: Entropy vs Gini')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the extracted features:\n",
    "> **Feature Group 1: Traffic Volume (Absolute)**  \n",
    "> - Feature 1: Number of incoming packets  \n",
    "> - Feature 2: Number of outgoing packets  \n",
    "> - Feature 3: Total number of packets  \n",
    "> \n",
    "> **Feature Group 2: Traffic Volume (Fraction)**\n",
    "> - Feature 1: Number of incoming packets as a fraction of the total number of packets  \n",
    "> - Feature 2: Number of outgoing packets as a fraction of the total number of packets \n",
    "> \n",
    "> **Feature Group 3: Traffic Ordering List**\n",
    "> - Feature 6: Standard deviation of the outgoing packets ordering list  \n",
    "> - Feature 7: Average of the outgoing packets ordering list  \n",
    "> \n",
    "> **Feature Group 4: Traffic concentration** \n",
    "> - Feature 8: Sum of all items in the alternative concentration feature list  \n",
    "> - Feature 9: Average of all items in the alternative concentration feature list  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noted that within each of the 4 feature groups, the features are likely to be highly correlated due to their similarity. Furthermore, feature groups 1 and 2 are closely related as well with 1 being an absolute measurement of traffic volume and 2 as the ratio. Hence we will be selecting 2 features from the combination of group 1 and 2, and 1 feature each from group 3 and 4.\n",
    "\n",
    "According to our feature importance analysis, we have selected the features to be\n",
    "1. Feature 2: Number of outgoing packets   \n",
    "2. Feature 3: Total number of packets\n",
    "3. Feature 7: Average of the outgoing packets ordering list \n",
    "4. Feature 8: Sum of all items in the alternative concentration feature list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = closed_world_df[['outgoing_packet_counts', 'total_packet_counts', 'avg_outgoing_order', 'sum_concentration']]\n",
    "y = closed_world_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing Model with selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we construct an arbitrary random forest classification model using arbitrarily chosen parameters. This section aims to explore the implementation of the model. These parameters will be tuned in the next section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outgoing_packet_counts</th>\n",
       "      <th>total_packet_counts</th>\n",
       "      <th>avg_outgoing_order</th>\n",
       "      <th>sum_concentration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6787</th>\n",
       "      <td>798</td>\n",
       "      <td>6393</td>\n",
       "      <td>3442.906015</td>\n",
       "      <td>49.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>392</td>\n",
       "      <td>9978</td>\n",
       "      <td>4233.829082</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11219</th>\n",
       "      <td>156</td>\n",
       "      <td>3483</td>\n",
       "      <td>1165.185897</td>\n",
       "      <td>12.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>80</td>\n",
       "      <td>1824</td>\n",
       "      <td>675.262500</td>\n",
       "      <td>5.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>786</td>\n",
       "      <td>9936</td>\n",
       "      <td>5420.637405</td>\n",
       "      <td>21.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       outgoing_packet_counts  total_packet_counts  avg_outgoing_order  \\\n",
       "6787                      798                 6393         3442.906015   \n",
       "6097                      392                 9978         4233.829082   \n",
       "11219                     156                 3483         1165.185897   \n",
       "2512                       80                 1824          675.262500   \n",
       "4279                      786                 9936         5420.637405   \n",
       "\n",
       "       sum_concentration  \n",
       "6787               49.43  \n",
       "6097               20.00  \n",
       "11219              12.92  \n",
       "2512                5.35  \n",
       "4279               21.67  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=100, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=100, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=100, random_state=42)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "clf_selected_features = RandomForestClassifier(n_estimators=100, criterion=\"entropy\", max_depth=100, min_samples_split=2, max_features=\"sqrt\", random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf_selected_features.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a process object to track current process\n",
    "process = psutil.Process(os.getpid())\n",
    "# tracking start memory\n",
    "memory_before = process.memory_info().rss / (1024 * 1024)\n",
    "# tracking start time\n",
    "start_time = time.time()\n",
    "# Make predictions on the train set\n",
    "y_train_pred = clf_selected_features.predict(X_train)\n",
    "# tracking end time\n",
    "end_time = time.time()\n",
    "# tracking end memory\n",
    "memory_after = process.memory_info().rss / (1024 * 1024)\n",
    "\n",
    "time_taken_selected_features_train = end_time - start_time\n",
    "memory_used_selected_features_train = memory_after - memory_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 0.2109375 MB\n",
      "Time taken to predict: 0.7040159702301025 seconds\n",
      "Model Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       158\n",
      "           1       1.00      1.00      1.00       158\n",
      "           2       1.00      1.00      1.00       165\n",
      "           3       1.00      1.00      1.00       171\n",
      "           4       1.00      1.00      1.00       161\n",
      "           5       1.00      1.00      1.00       155\n",
      "           6       1.00      1.00      1.00       156\n",
      "           7       1.00      1.00      1.00       164\n",
      "           8       1.00      1.00      1.00       166\n",
      "           9       1.00      1.00      1.00       169\n",
      "          10       1.00      1.00      1.00       153\n",
      "          11       1.00      1.00      1.00       165\n",
      "          12       1.00      1.00      1.00       158\n",
      "          13       1.00      1.00      1.00       160\n",
      "          14       1.00      1.00      1.00       164\n",
      "          15       1.00      1.00      1.00       165\n",
      "          16       1.00      1.00      1.00       157\n",
      "          17       1.00      1.00      1.00       153\n",
      "          18       1.00      1.00      1.00       163\n",
      "          19       1.00      1.00      1.00       163\n",
      "          20       1.00      1.00      1.00       156\n",
      "          21       1.00      1.00      1.00       159\n",
      "          22       1.00      1.00      1.00       160\n",
      "          23       1.00      1.00      1.00       165\n",
      "          24       1.00      1.00      1.00       154\n",
      "          25       1.00      1.00      1.00       164\n",
      "          26       1.00      1.00      1.00       163\n",
      "          27       1.00      1.00      1.00       155\n",
      "          28       1.00      1.00      1.00       164\n",
      "          29       1.00      1.00      1.00       153\n",
      "          30       1.00      1.00      1.00       154\n",
      "          31       1.00      1.00      1.00       163\n",
      "          32       1.00      1.00      1.00       162\n",
      "          33       1.00      1.00      1.00       163\n",
      "          34       1.00      1.00      1.00       159\n",
      "          35       1.00      1.00      1.00       162\n",
      "          36       1.00      1.00      1.00       165\n",
      "          37       1.00      1.00      1.00       147\n",
      "          38       1.00      1.00      1.00       147\n",
      "          39       1.00      1.00      1.00       154\n",
      "          40       1.00      1.00      1.00       149\n",
      "          41       1.00      1.00      1.00       157\n",
      "          42       1.00      1.00      1.00       161\n",
      "          43       1.00      1.00      1.00       159\n",
      "          44       1.00      1.00      1.00       156\n",
      "          45       1.00      1.00      1.00       165\n",
      "          46       1.00      1.00      1.00       165\n",
      "          47       1.00      1.00      1.00       161\n",
      "          48       1.00      1.00      1.00       163\n",
      "          49       1.00      1.00      1.00       157\n",
      "          50       1.00      1.00      1.00       168\n",
      "          51       1.00      1.00      1.00       162\n",
      "          52       1.00      1.00      1.00       151\n",
      "          53       1.00      1.00      1.00       169\n",
      "          54       1.00      1.00      1.00       153\n",
      "          55       1.00      1.00      1.00       159\n",
      "          56       1.00      1.00      1.00       153\n",
      "          57       1.00      1.00      1.00       164\n",
      "          58       1.00      1.00      1.00       165\n",
      "          59       1.00      1.00      1.00       161\n",
      "          60       1.00      1.00      1.00       160\n",
      "          61       1.00      1.00      1.00       144\n",
      "          62       1.00      1.00      1.00       143\n",
      "          63       1.00      1.00      1.00       173\n",
      "          64       1.00      1.00      1.00       161\n",
      "          65       1.00      1.00      1.00       165\n",
      "          66       1.00      1.00      1.00       154\n",
      "          67       1.00      1.00      1.00       163\n",
      "          68       1.00      1.00      1.00       152\n",
      "          69       1.00      1.00      1.00       157\n",
      "          70       1.00      1.00      1.00       166\n",
      "          71       1.00      1.00      1.00       164\n",
      "          72       1.00      1.00      1.00       161\n",
      "          73       1.00      1.00      1.00       159\n",
      "          74       1.00      1.00      1.00       147\n",
      "          75       1.00      1.00      1.00       163\n",
      "          76       1.00      1.00      1.00       156\n",
      "          77       1.00      1.00      1.00       170\n",
      "          78       1.00      1.00      1.00       164\n",
      "          79       1.00      1.00      1.00       170\n",
      "          80       1.00      1.00      1.00       160\n",
      "          81       1.00      1.00      1.00       155\n",
      "          82       1.00      1.00      1.00       155\n",
      "          83       1.00      1.00      1.00       169\n",
      "          84       1.00      1.00      1.00       160\n",
      "          85       1.00      1.00      1.00       156\n",
      "          86       1.00      1.00      1.00       163\n",
      "          87       1.00      1.00      1.00       165\n",
      "          88       1.00      1.00      1.00       163\n",
      "          89       1.00      1.00      1.00       162\n",
      "          90       1.00      1.00      1.00       164\n",
      "          91       1.00      1.00      1.00       161\n",
      "          92       1.00      1.00      1.00       165\n",
      "          93       1.00      1.00      1.00       161\n",
      "          94       1.00      1.00      1.00       158\n",
      "\n",
      "    accuracy                           1.00     15200\n",
      "   macro avg       1.00      1.00      1.00     15200\n",
      "weighted avg       1.00      1.00      1.00     15200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy and other metrics\n",
    "print(\"Memory used:\", memory_used_selected_features_train, \"MB\")\n",
    "print(\"Time taken to predict:\", time_taken_selected_features_train, \"seconds\")\n",
    "print(\"Model Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a process object to track current process\n",
    "process = psutil.Process(os.getpid())\n",
    "# tracking start memory\n",
    "memory_before = process.memory_info().rss / (1024 * 1024)\n",
    "# tracking start time\n",
    "start_time = time.time()\n",
    "# Make predictions on the test set\n",
    "y_test_pred = clf_selected_features.predict(X_test)\n",
    "# tracking end time\n",
    "end_time = time.time()\n",
    "# tracking end memory\n",
    "memory_after = process.memory_info().rss / (1024 * 1024)\n",
    "\n",
    "time_taken_selected_features_test = end_time - start_time\n",
    "memory_used_selected_features_test = memory_after - memory_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 0.0 MB\n",
      "Time taken to predict: 0.16006040573120117 seconds\n",
      "Model Accuracy: 0.6942105263157895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63        42\n",
      "           1       0.52      0.33      0.41        42\n",
      "           2       0.74      0.89      0.81        35\n",
      "           3       0.76      0.86      0.81        29\n",
      "           4       0.75      0.85      0.80        39\n",
      "           5       0.78      0.84      0.81        45\n",
      "           6       0.82      0.82      0.82        44\n",
      "           7       0.59      0.61      0.60        36\n",
      "           8       0.59      0.68      0.63        34\n",
      "           9       0.61      0.61      0.61        31\n",
      "          10       0.87      0.72      0.79        47\n",
      "          11       0.62      0.69      0.65        35\n",
      "          12       0.87      0.79      0.82        42\n",
      "          13       0.60      0.45      0.51        40\n",
      "          14       0.50      0.39      0.44        36\n",
      "          15       0.76      0.71      0.74        35\n",
      "          16       0.84      0.72      0.78        43\n",
      "          17       0.64      0.57      0.61        47\n",
      "          18       0.75      0.81      0.78        37\n",
      "          19       0.56      0.68      0.61        37\n",
      "          20       0.87      0.93      0.90        44\n",
      "          21       0.52      0.41      0.46        41\n",
      "          22       0.58      0.65      0.61        40\n",
      "          23       0.78      0.83      0.81        35\n",
      "          24       0.32      0.26      0.29        46\n",
      "          25       0.59      0.56      0.57        36\n",
      "          26       0.71      0.86      0.78        37\n",
      "          27       0.69      0.44      0.54        45\n",
      "          28       0.82      0.75      0.78        36\n",
      "          29       0.58      0.64      0.61        47\n",
      "          30       0.64      0.76      0.69        46\n",
      "          31       0.72      0.76      0.74        37\n",
      "          32       0.62      0.66      0.64        38\n",
      "          33       0.65      0.92      0.76        37\n",
      "          34       0.45      0.51      0.48        41\n",
      "          35       0.67      0.82      0.74        38\n",
      "          36       0.82      0.77      0.79        35\n",
      "          37       0.60      0.55      0.57        53\n",
      "          38       0.67      0.64      0.65        53\n",
      "          39       0.82      0.70      0.75        46\n",
      "          40       0.72      0.57      0.64        51\n",
      "          41       0.77      0.84      0.80        43\n",
      "          42       0.53      0.41      0.46        39\n",
      "          43       0.82      0.90      0.86        41\n",
      "          44       0.91      0.95      0.93        44\n",
      "          45       0.44      0.49      0.46        35\n",
      "          46       0.79      0.63      0.70        35\n",
      "          47       0.57      0.51      0.54        39\n",
      "          48       0.64      0.76      0.69        37\n",
      "          49       0.79      0.70      0.74        43\n",
      "          50       0.56      0.69      0.62        32\n",
      "          51       0.57      0.55      0.56        38\n",
      "          52       0.67      0.65      0.66        49\n",
      "          53       0.59      0.65      0.62        31\n",
      "          54       0.90      0.74      0.81        47\n",
      "          55       0.60      0.63      0.62        41\n",
      "          56       0.93      0.89      0.91        47\n",
      "          57       0.93      0.72      0.81        36\n",
      "          58       0.81      0.83      0.82        35\n",
      "          59       0.71      0.82      0.76        39\n",
      "          60       0.71      0.85      0.77        40\n",
      "          61       0.70      0.68      0.69        56\n",
      "          62       0.86      0.75      0.80        57\n",
      "          63       0.56      0.67      0.61        27\n",
      "          64       0.69      0.62      0.65        39\n",
      "          65       0.65      0.63      0.64        35\n",
      "          66       0.73      0.76      0.74        46\n",
      "          67       0.79      0.81      0.80        37\n",
      "          68       0.70      0.44      0.54        48\n",
      "          69       0.62      0.60      0.61        43\n",
      "          70       0.91      0.94      0.93        34\n",
      "          71       0.65      0.67      0.66        36\n",
      "          72       0.68      0.69      0.68        39\n",
      "          73       0.82      0.90      0.86        41\n",
      "          74       0.71      0.55      0.62        53\n",
      "          75       0.92      0.97      0.95        37\n",
      "          76       0.91      0.93      0.92        44\n",
      "          77       0.56      0.60      0.58        30\n",
      "          78       0.44      0.44      0.44        36\n",
      "          79       0.40      0.60      0.48        30\n",
      "          80       0.77      0.85      0.81        40\n",
      "          81       0.64      0.71      0.67        45\n",
      "          82       0.71      0.49      0.58        45\n",
      "          83       0.65      0.90      0.76        31\n",
      "          84       0.72      0.78      0.75        40\n",
      "          85       0.85      0.80      0.82        44\n",
      "          86       0.92      0.95      0.93        37\n",
      "          87       0.72      0.66      0.69        35\n",
      "          88       0.62      0.70      0.66        37\n",
      "          89       0.65      0.58      0.61        38\n",
      "          90       0.63      0.75      0.68        36\n",
      "          91       0.62      0.72      0.67        39\n",
      "          92       0.69      0.69      0.69        35\n",
      "          93       0.90      0.97      0.94        39\n",
      "          94       0.52      0.57      0.55        42\n",
      "\n",
      "    accuracy                           0.69      3800\n",
      "   macro avg       0.69      0.70      0.69      3800\n",
      "weighted avg       0.70      0.69      0.69      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy and other metrics\n",
    "print(\"Memory used:\", memory_used_selected_features_test, \"MB\")\n",
    "print(\"Time taken to predict:\", time_taken_selected_features_test, \"seconds\")\n",
    "print(\"Model Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will be using Grid Search to tune our model parameters for our Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the parameter grid for the Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [10, 15],\n",
    "    'min_samples_leaf': [5, 10],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True],\n",
    "    'criterion': ['gini', 'entropy']           \n",
    "}\n",
    "\n",
    "# Defining the grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  \n",
    "    refit=True, \n",
    "    verbose = 3,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    }
   ],
   "source": [
    "# Fitting the grid search\n",
    "start_time = time.time()\n",
    "grid.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "time_taken_grid_search = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for grid search: 833.7051796913147 seconds\n"
     ]
    }
   ],
   "source": [
    "# Print the time taken to perform the grid search\n",
    "print(\"Time taken for grid search:\", time_taken_grid_search, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Print best parameters after grid search\n",
    "print(\"Best parameters found:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a process object to track current process\n",
    "process = psutil.Process(os.getpid())\n",
    "# tracking start memory\n",
    "memory_before = process.memory_info().rss / (1024 * 1024)\n",
    "# tracking start time\n",
    "start_time = time.time()\n",
    "# Make predictions on the test set\n",
    "y_train_pred = grid.predict(X_train)\n",
    "# tracking end time\n",
    "end_time = time.time()\n",
    "# tracking end memory\n",
    "memory_after = process.memory_info().rss / (1024 * 1024)\n",
    "\n",
    "time_taken_selected_features_tuned_train = end_time - start_time\n",
    "memory_used_selected_features_tuned_train = memory_after - memory_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 0.1484375 MB\n",
      "Time taken to predict: 1.244154691696167 seconds\n",
      "Model Accuracy: 0.8431578947368421\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88       158\n",
      "           1       0.94      0.63      0.75       158\n",
      "           2       0.87      0.92      0.89       165\n",
      "           3       0.87      0.89      0.88       171\n",
      "           4       0.87      0.91      0.89       161\n",
      "           5       0.90      0.85      0.88       155\n",
      "           6       0.81      0.93      0.86       156\n",
      "           7       0.82      0.90      0.85       164\n",
      "           8       0.84      0.87      0.85       166\n",
      "           9       0.82      0.90      0.86       169\n",
      "          10       0.87      0.77      0.82       153\n",
      "          11       0.82      0.77      0.80       165\n",
      "          12       0.92      0.94      0.93       158\n",
      "          13       0.90      0.70      0.79       160\n",
      "          14       0.89      0.77      0.83       164\n",
      "          15       0.84      0.92      0.88       165\n",
      "          16       0.93      0.73      0.81       157\n",
      "          17       0.79      0.80      0.79       153\n",
      "          18       0.87      0.91      0.89       163\n",
      "          19       0.83      0.82      0.82       163\n",
      "          20       0.88      0.99      0.93       156\n",
      "          21       0.88      0.74      0.81       159\n",
      "          22       0.85      0.79      0.82       160\n",
      "          23       0.87      0.92      0.89       165\n",
      "          24       0.66      0.64      0.65       154\n",
      "          25       0.84      0.74      0.79       164\n",
      "          26       0.82      0.95      0.88       163\n",
      "          27       0.88      0.82      0.85       155\n",
      "          28       0.94      0.82      0.88       164\n",
      "          29       0.78      0.83      0.80       153\n",
      "          30       0.75      0.88      0.81       154\n",
      "          31       0.90      0.89      0.89       163\n",
      "          32       0.84      0.85      0.84       162\n",
      "          33       0.86      0.80      0.83       163\n",
      "          34       0.78      0.71      0.75       159\n",
      "          35       0.85      0.94      0.89       162\n",
      "          36       0.86      0.88      0.87       165\n",
      "          37       0.86      0.69      0.77       147\n",
      "          38       0.77      0.93      0.84       147\n",
      "          39       0.89      0.86      0.87       154\n",
      "          40       0.84      0.81      0.82       149\n",
      "          41       0.87      0.92      0.89       157\n",
      "          42       0.81      0.76      0.78       161\n",
      "          43       0.83      0.92      0.87       159\n",
      "          44       0.89      0.98      0.93       156\n",
      "          45       0.77      0.72      0.74       165\n",
      "          46       0.89      0.76      0.82       165\n",
      "          47       0.84      0.79      0.81       161\n",
      "          48       0.87      0.90      0.88       163\n",
      "          49       0.91      0.94      0.92       157\n",
      "          50       0.83      0.80      0.82       168\n",
      "          51       0.79      0.76      0.78       162\n",
      "          52       0.87      0.77      0.82       151\n",
      "          53       0.74      0.82      0.78       169\n",
      "          54       0.91      0.90      0.90       153\n",
      "          55       0.80      0.74      0.77       159\n",
      "          56       0.94      0.97      0.96       153\n",
      "          57       0.86      0.81      0.84       164\n",
      "          58       0.87      0.94      0.90       165\n",
      "          59       0.85      0.88      0.86       161\n",
      "          60       0.84      0.88      0.86       160\n",
      "          61       0.77      0.85      0.81       144\n",
      "          62       0.83      0.83      0.83       143\n",
      "          63       0.84      0.75      0.79       173\n",
      "          64       0.87      0.75      0.81       161\n",
      "          65       0.76      0.84      0.80       165\n",
      "          66       0.84      0.86      0.85       154\n",
      "          67       0.85      0.88      0.86       163\n",
      "          68       0.89      0.82      0.85       152\n",
      "          69       0.74      0.76      0.75       157\n",
      "          70       0.92      0.99      0.96       166\n",
      "          71       0.80      0.80      0.80       164\n",
      "          72       0.87      0.79      0.83       161\n",
      "          73       0.89      0.95      0.92       159\n",
      "          74       0.71      0.85      0.77       147\n",
      "          75       0.93      0.99      0.96       163\n",
      "          76       0.94      0.95      0.94       156\n",
      "          77       0.83      0.67      0.74       170\n",
      "          78       0.81      0.73      0.77       164\n",
      "          79       0.84      0.82      0.83       170\n",
      "          80       0.87      0.94      0.91       160\n",
      "          81       0.83      0.86      0.85       155\n",
      "          82       0.86      0.74      0.79       155\n",
      "          83       0.79      0.93      0.85       169\n",
      "          84       0.81      0.79      0.80       160\n",
      "          85       0.88      0.92      0.90       156\n",
      "          86       0.87      0.99      0.93       163\n",
      "          87       0.85      0.92      0.88       165\n",
      "          88       0.89      0.86      0.87       163\n",
      "          89       0.75      0.81      0.78       162\n",
      "          90       0.76      0.81      0.79       164\n",
      "          91       0.85      0.88      0.87       161\n",
      "          92       0.81      0.76      0.79       165\n",
      "          93       0.88      0.93      0.90       161\n",
      "          94       0.79      0.84      0.81       158\n",
      "\n",
      "    accuracy                           0.84     15200\n",
      "   macro avg       0.84      0.84      0.84     15200\n",
      "weighted avg       0.85      0.84      0.84     15200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy and other metrics\n",
    "print(\"Memory used:\", memory_used_selected_features_tuned_train, \"MB\")\n",
    "print(\"Time taken to predict:\", time_taken_selected_features_tuned_train, \"seconds\")\n",
    "print(\"Model Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a process object to track current process\n",
    "process = psutil.Process(os.getpid())\n",
    "# tracking start memory\n",
    "memory_before = process.memory_info().rss / (1024 * 1024)\n",
    "# tracking start time\n",
    "start_time = time.time()\n",
    "# Make predictions on the test set\n",
    "y_test_pred = grid.predict(X_test)\n",
    "# tracking end time\n",
    "end_time = time.time()\n",
    "# tracking end memory\n",
    "memory_after = process.memory_info().rss / (1024 * 1024)\n",
    "\n",
    "time_taken_selected_features_tuned_test = end_time - start_time\n",
    "memory_used_selected_features_tuned_test = memory_after - memory_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 0.12890625 MB\n",
      "Time taken to predict: 0.2712867259979248 seconds\n",
      "Model Accuracy: 0.6686842105263158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.57      0.63        42\n",
      "           1       0.50      0.29      0.36        42\n",
      "           2       0.69      0.83      0.75        35\n",
      "           3       0.81      0.76      0.79        29\n",
      "           4       0.68      0.72      0.70        39\n",
      "           5       0.75      0.73      0.74        45\n",
      "           6       0.70      0.80      0.74        44\n",
      "           7       0.58      0.61      0.59        36\n",
      "           8       0.57      0.71      0.63        34\n",
      "           9       0.42      0.61      0.50        31\n",
      "          10       0.81      0.62      0.70        47\n",
      "          11       0.62      0.66      0.64        35\n",
      "          12       0.83      0.81      0.82        42\n",
      "          13       0.65      0.50      0.56        40\n",
      "          14       0.68      0.36      0.47        36\n",
      "          15       0.74      0.71      0.72        35\n",
      "          16       0.91      0.70      0.79        43\n",
      "          17       0.64      0.57      0.61        47\n",
      "          18       0.67      0.78      0.72        37\n",
      "          19       0.52      0.59      0.56        37\n",
      "          20       0.80      0.93      0.86        44\n",
      "          21       0.55      0.44      0.49        41\n",
      "          22       0.55      0.57      0.56        40\n",
      "          23       0.79      0.77      0.78        35\n",
      "          24       0.39      0.28      0.33        46\n",
      "          25       0.62      0.44      0.52        36\n",
      "          26       0.64      0.95      0.76        37\n",
      "          27       0.64      0.40      0.49        45\n",
      "          28       0.82      0.75      0.78        36\n",
      "          29       0.57      0.57      0.57        47\n",
      "          30       0.54      0.72      0.62        46\n",
      "          31       0.74      0.68      0.70        37\n",
      "          32       0.58      0.58      0.58        38\n",
      "          33       0.68      0.86      0.76        37\n",
      "          34       0.53      0.41      0.47        41\n",
      "          35       0.66      0.82      0.73        38\n",
      "          36       0.79      0.74      0.76        35\n",
      "          37       0.69      0.47      0.56        53\n",
      "          38       0.60      0.66      0.63        53\n",
      "          39       0.84      0.67      0.75        46\n",
      "          40       0.61      0.55      0.58        51\n",
      "          41       0.77      0.79      0.78        43\n",
      "          42       0.44      0.49      0.46        39\n",
      "          43       0.78      0.88      0.83        41\n",
      "          44       0.88      0.98      0.92        44\n",
      "          45       0.45      0.51      0.48        35\n",
      "          46       0.74      0.66      0.70        35\n",
      "          47       0.63      0.56      0.59        39\n",
      "          48       0.68      0.70      0.69        37\n",
      "          49       0.74      0.74      0.74        43\n",
      "          50       0.51      0.62      0.56        32\n",
      "          51       0.57      0.45      0.50        38\n",
      "          52       0.76      0.69      0.72        49\n",
      "          53       0.58      0.68      0.63        31\n",
      "          54       0.84      0.77      0.80        47\n",
      "          55       0.59      0.54      0.56        41\n",
      "          56       0.95      0.89      0.92        47\n",
      "          57       0.92      0.61      0.73        36\n",
      "          58       0.78      0.83      0.81        35\n",
      "          59       0.73      0.82      0.77        39\n",
      "          60       0.75      0.82      0.79        40\n",
      "          61       0.71      0.66      0.69        56\n",
      "          62       0.80      0.75      0.77        57\n",
      "          63       0.55      0.67      0.60        27\n",
      "          64       0.65      0.56      0.60        39\n",
      "          65       0.55      0.60      0.58        35\n",
      "          66       0.76      0.76      0.76        46\n",
      "          67       0.60      0.81      0.69        37\n",
      "          68       0.68      0.35      0.47        48\n",
      "          69       0.64      0.65      0.64        43\n",
      "          70       0.84      0.94      0.89        34\n",
      "          71       0.64      0.64      0.64        36\n",
      "          72       0.67      0.62      0.64        39\n",
      "          73       0.75      0.88      0.81        41\n",
      "          74       0.58      0.58      0.58        53\n",
      "          75       0.83      0.92      0.87        37\n",
      "          76       0.93      0.93      0.93        44\n",
      "          77       0.57      0.53      0.55        30\n",
      "          78       0.42      0.36      0.39        36\n",
      "          79       0.38      0.60      0.47        30\n",
      "          80       0.79      0.85      0.82        40\n",
      "          81       0.59      0.67      0.62        45\n",
      "          82       0.79      0.42      0.55        45\n",
      "          83       0.54      0.84      0.66        31\n",
      "          84       0.72      0.72      0.72        40\n",
      "          85       0.87      0.77      0.82        44\n",
      "          86       0.83      0.95      0.89        37\n",
      "          87       0.70      0.66      0.68        35\n",
      "          88       0.59      0.65      0.62        37\n",
      "          89       0.49      0.58      0.53        38\n",
      "          90       0.62      0.69      0.66        36\n",
      "          91       0.49      0.69      0.57        39\n",
      "          92       0.63      0.63      0.63        35\n",
      "          93       0.76      0.95      0.84        39\n",
      "          94       0.49      0.57      0.53        42\n",
      "\n",
      "    accuracy                           0.67      3800\n",
      "   macro avg       0.67      0.67      0.66      3800\n",
      "weighted avg       0.67      0.67      0.66      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy and other metrics\n",
    "print(\"Memory used:\", memory_used_selected_features_tuned_test, \"MB\")\n",
    "print(\"Time taken to predict:\", time_taken_selected_features_tuned_test, \"seconds\")\n",
    "print(\"Model Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
