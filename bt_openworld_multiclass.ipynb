{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be building our model for the open-world experiments to multi-class classify 95 monitored website traces with unique labels against additional unmonitored websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import psutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we will first import the dataframes into this notebook. Run either 1 of these blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using Google Colab, run this block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Use this with colab\n",
    "print(\"Loading datafile...\")\n",
    "with open('datasets/extracted_features.pkl', 'rb') as f:\n",
    "    extracted_df = pickle.load(f)\n",
    "print (\"Data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using local, run this block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Use this for local (change the directory to where the extracted_features.pkl is stored on your local machine)\n",
    "# Load the pickle file\n",
    "print(\"Loading datafile...\")\n",
    "# change this directory to the directory where mon_standard.pkl is stored on your local machine\n",
    "file_path = r'C:\\EWHA\\Term 2\\Machine Learning\\pro\\neurotic_networkers\\extracted_features.pkl' # Jordans local path\n",
    "with open(file_path, 'rb') as f: # Path to extracted_features.pkl in Colab\n",
    "    extracted_df = pickle.load(f)\n",
    "print (\"Data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>incoming_packet_counts</th>\n",
       "      <th>outgoing_packet_counts</th>\n",
       "      <th>total_packet_counts</th>\n",
       "      <th>incoming_packet_fraction</th>\n",
       "      <th>outgoing_packet_fraction</th>\n",
       "      <th>std_outgoing_order</th>\n",
       "      <th>avg_outgoing_order</th>\n",
       "      <th>sum_concentration</th>\n",
       "      <th>avg_concentration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1300</td>\n",
       "      <td>121</td>\n",
       "      <td>1421</td>\n",
       "      <td>0.914849</td>\n",
       "      <td>0.085151</td>\n",
       "      <td>515.483953</td>\n",
       "      <td>773.322314</td>\n",
       "      <td>10.14</td>\n",
       "      <td>0.007136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>438</td>\n",
       "      <td>80</td>\n",
       "      <td>518</td>\n",
       "      <td>0.845560</td>\n",
       "      <td>0.154440</td>\n",
       "      <td>139.231951</td>\n",
       "      <td>226.162500</td>\n",
       "      <td>10.16</td>\n",
       "      <td>0.019614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1240</td>\n",
       "      <td>118</td>\n",
       "      <td>1358</td>\n",
       "      <td>0.913108</td>\n",
       "      <td>0.086892</td>\n",
       "      <td>472.735508</td>\n",
       "      <td>786.110169</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.008181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1324</td>\n",
       "      <td>122</td>\n",
       "      <td>1446</td>\n",
       "      <td>0.915629</td>\n",
       "      <td>0.084371</td>\n",
       "      <td>513.916038</td>\n",
       "      <td>820.139344</td>\n",
       "      <td>13.36</td>\n",
       "      <td>0.009239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1291</td>\n",
       "      <td>115</td>\n",
       "      <td>1406</td>\n",
       "      <td>0.918208</td>\n",
       "      <td>0.081792</td>\n",
       "      <td>503.993490</td>\n",
       "      <td>789.608696</td>\n",
       "      <td>10.64</td>\n",
       "      <td>0.007568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28995</th>\n",
       "      <td>-1</td>\n",
       "      <td>4180</td>\n",
       "      <td>413</td>\n",
       "      <td>4593</td>\n",
       "      <td>0.910081</td>\n",
       "      <td>0.089919</td>\n",
       "      <td>1173.380403</td>\n",
       "      <td>2549.414044</td>\n",
       "      <td>32.09</td>\n",
       "      <td>0.006987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28996</th>\n",
       "      <td>-1</td>\n",
       "      <td>4663</td>\n",
       "      <td>447</td>\n",
       "      <td>5110</td>\n",
       "      <td>0.912524</td>\n",
       "      <td>0.087476</td>\n",
       "      <td>1621.869237</td>\n",
       "      <td>3062.015660</td>\n",
       "      <td>38.62</td>\n",
       "      <td>0.007558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28997</th>\n",
       "      <td>-1</td>\n",
       "      <td>302</td>\n",
       "      <td>59</td>\n",
       "      <td>361</td>\n",
       "      <td>0.836565</td>\n",
       "      <td>0.163435</td>\n",
       "      <td>118.245320</td>\n",
       "      <td>179.101695</td>\n",
       "      <td>34.93</td>\n",
       "      <td>0.096759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28998</th>\n",
       "      <td>-1</td>\n",
       "      <td>413</td>\n",
       "      <td>96</td>\n",
       "      <td>509</td>\n",
       "      <td>0.811395</td>\n",
       "      <td>0.188605</td>\n",
       "      <td>166.667122</td>\n",
       "      <td>309.197917</td>\n",
       "      <td>11.84</td>\n",
       "      <td>0.023261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28999</th>\n",
       "      <td>-1</td>\n",
       "      <td>9668</td>\n",
       "      <td>322</td>\n",
       "      <td>9990</td>\n",
       "      <td>0.967768</td>\n",
       "      <td>0.032232</td>\n",
       "      <td>3076.060409</td>\n",
       "      <td>4627.602484</td>\n",
       "      <td>9.62</td>\n",
       "      <td>0.000963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  incoming_packet_counts  outgoing_packet_counts  \\\n",
       "0          0                    1300                     121   \n",
       "1          0                     438                      80   \n",
       "2          0                    1240                     118   \n",
       "3          0                    1324                     122   \n",
       "4          0                    1291                     115   \n",
       "...      ...                     ...                     ...   \n",
       "28995     -1                    4180                     413   \n",
       "28996     -1                    4663                     447   \n",
       "28997     -1                     302                      59   \n",
       "28998     -1                     413                      96   \n",
       "28999     -1                    9668                     322   \n",
       "\n",
       "       total_packet_counts  incoming_packet_fraction  \\\n",
       "0                     1421                  0.914849   \n",
       "1                      518                  0.845560   \n",
       "2                     1358                  0.913108   \n",
       "3                     1446                  0.915629   \n",
       "4                     1406                  0.918208   \n",
       "...                    ...                       ...   \n",
       "28995                 4593                  0.910081   \n",
       "28996                 5110                  0.912524   \n",
       "28997                  361                  0.836565   \n",
       "28998                  509                  0.811395   \n",
       "28999                 9990                  0.967768   \n",
       "\n",
       "       outgoing_packet_fraction  std_outgoing_order  avg_outgoing_order  \\\n",
       "0                      0.085151          515.483953          773.322314   \n",
       "1                      0.154440          139.231951          226.162500   \n",
       "2                      0.086892          472.735508          786.110169   \n",
       "3                      0.084371          513.916038          820.139344   \n",
       "4                      0.081792          503.993490          789.608696   \n",
       "...                         ...                 ...                 ...   \n",
       "28995                  0.089919         1173.380403         2549.414044   \n",
       "28996                  0.087476         1621.869237         3062.015660   \n",
       "28997                  0.163435          118.245320          179.101695   \n",
       "28998                  0.188605          166.667122          309.197917   \n",
       "28999                  0.032232         3076.060409         4627.602484   \n",
       "\n",
       "       sum_concentration  avg_concentration  \n",
       "0                  10.14           0.007136  \n",
       "1                  10.16           0.019614  \n",
       "2                  11.11           0.008181  \n",
       "3                  13.36           0.009239  \n",
       "4                  10.64           0.007568  \n",
       "...                  ...                ...  \n",
       "28995              32.09           0.006987  \n",
       "28996              38.62           0.007558  \n",
       "28997              34.93           0.096759  \n",
       "28998              11.84           0.023261  \n",
       "28999               9.62           0.000963  \n",
       "\n",
       "[29000 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_initial = extracted_df.drop(columns=['label'])\n",
    "y_initial = extracted_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing Model with all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we construct a model using all of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_initial_train, X_initial_test, y_initial_train, y_initial_test = train_test_split(\n",
    "    X_initial, y_initial, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=100, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=100, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=100, random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "clf_all_features = RandomForestClassifier(n_estimators=100, criterion=\"entropy\", max_depth=100, min_samples_split=2, max_features=\"sqrt\", random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf_all_features.fit(X_initial_train, y_initial_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a process object to track current process\n",
    "process = psutil.Process(os.getpid())\n",
    "# tracking start time\n",
    "start_time = time.time()\n",
    "# Make predictions on the train set\n",
    "y_initial_train_pred = clf_all_features.predict(X_initial_train)\n",
    "# tracking end time\n",
    "end_time = time.time()\n",
    "\n",
    "time_taken_all_features_train = end_time - start_time\n",
    "memory_used_all_features_train = process.memory_info().rss / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 1088.046875 MB\n",
      "Time taken to predict: 1.8507726192474365 seconds\n",
      "Model Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00      8023\n",
      "           0       1.00      1.00      1.00       165\n",
      "           1       1.00      1.00      1.00       162\n",
      "           2       1.00      1.00      1.00       163\n",
      "           3       1.00      1.00      1.00       164\n",
      "           4       1.00      1.00      1.00       166\n",
      "           5       1.00      1.00      1.00       164\n",
      "           6       1.00      1.00      1.00       165\n",
      "           7       1.00      1.00      1.00       153\n",
      "           8       1.00      1.00      1.00       161\n",
      "           9       1.00      1.00      1.00       168\n",
      "          10       1.00      1.00      1.00       167\n",
      "          11       1.00      1.00      1.00       155\n",
      "          12       1.00      1.00      1.00       157\n",
      "          13       1.00      1.00      1.00       160\n",
      "          14       1.00      1.00      1.00       156\n",
      "          15       1.00      1.00      1.00       163\n",
      "          16       1.00      1.00      1.00       160\n",
      "          17       1.00      1.00      1.00       158\n",
      "          18       1.00      1.00      1.00       160\n",
      "          19       1.00      1.00      1.00       168\n",
      "          20       1.00      1.00      1.00       156\n",
      "          21       1.00      1.00      1.00       160\n",
      "          22       1.00      1.00      1.00       162\n",
      "          23       1.00      1.00      1.00       162\n",
      "          24       1.00      1.00      1.00       162\n",
      "          25       1.00      1.00      1.00       161\n",
      "          26       1.00      1.00      1.00       158\n",
      "          27       1.00      1.00      1.00       155\n",
      "          28       1.00      1.00      1.00       159\n",
      "          29       1.00      1.00      1.00       169\n",
      "          30       1.00      1.00      1.00       164\n",
      "          31       1.00      1.00      1.00       158\n",
      "          32       1.00      1.00      1.00       158\n",
      "          33       1.00      1.00      1.00       156\n",
      "          34       1.00      1.00      1.00       163\n",
      "          35       1.00      1.00      1.00       165\n",
      "          36       1.00      1.00      1.00       167\n",
      "          37       1.00      1.00      1.00       155\n",
      "          38       1.00      1.00      1.00       155\n",
      "          39       1.00      1.00      1.00       160\n",
      "          40       1.00      1.00      1.00       149\n",
      "          41       1.00      1.00      1.00       156\n",
      "          42       1.00      1.00      1.00       163\n",
      "          43       1.00      1.00      1.00       165\n",
      "          44       1.00      1.00      1.00       160\n",
      "          45       1.00      1.00      1.00       153\n",
      "          46       1.00      1.00      1.00       159\n",
      "          47       1.00      1.00      1.00       160\n",
      "          48       1.00      1.00      1.00       158\n",
      "          49       1.00      1.00      1.00       158\n",
      "          50       1.00      1.00      1.00       158\n",
      "          51       1.00      1.00      1.00       150\n",
      "          52       1.00      1.00      1.00       157\n",
      "          53       1.00      1.00      1.00       170\n",
      "          54       1.00      1.00      1.00       153\n",
      "          55       1.00      1.00      1.00       161\n",
      "          56       1.00      1.00      1.00       160\n",
      "          57       1.00      1.00      1.00       167\n",
      "          58       1.00      1.00      1.00       157\n",
      "          59       1.00      1.00      1.00       156\n",
      "          60       1.00      1.00      1.00       155\n",
      "          61       1.00      1.00      1.00       154\n",
      "          62       1.00      1.00      1.00       151\n",
      "          63       1.00      1.00      1.00       157\n",
      "          64       1.00      1.00      1.00       169\n",
      "          65       1.00      1.00      1.00       149\n",
      "          66       1.00      1.00      1.00       168\n",
      "          67       1.00      1.00      1.00       155\n",
      "          68       1.00      1.00      1.00       163\n",
      "          69       1.00      1.00      1.00       164\n",
      "          70       1.00      1.00      1.00       160\n",
      "          71       1.00      1.00      1.00       163\n",
      "          72       1.00      1.00      1.00       152\n",
      "          73       1.00      1.00      1.00       154\n",
      "          74       1.00      1.00      1.00       148\n",
      "          75       1.00      1.00      1.00       160\n",
      "          76       1.00      1.00      1.00       164\n",
      "          77       1.00      1.00      1.00       150\n",
      "          78       1.00      1.00      1.00       157\n",
      "          79       1.00      1.00      1.00       156\n",
      "          80       1.00      1.00      1.00       158\n",
      "          81       1.00      1.00      1.00       166\n",
      "          82       1.00      1.00      1.00       157\n",
      "          83       1.00      1.00      1.00       163\n",
      "          84       1.00      1.00      1.00       164\n",
      "          85       1.00      1.00      1.00       157\n",
      "          86       1.00      1.00      1.00       163\n",
      "          87       1.00      1.00      1.00       161\n",
      "          88       1.00      1.00      1.00       160\n",
      "          89       1.00      1.00      1.00       165\n",
      "          90       1.00      1.00      1.00       165\n",
      "          91       1.00      1.00      1.00       168\n",
      "          92       1.00      1.00      1.00       158\n",
      "          93       1.00      1.00      1.00       149\n",
      "          94       1.00      1.00      1.00       164\n",
      "\n",
      "    accuracy                           1.00     23200\n",
      "   macro avg       1.00      1.00      1.00     23200\n",
      "weighted avg       1.00      1.00      1.00     23200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy and other metrics\n",
    "print(\"Memory used:\", memory_used_all_features_train, \"MB\")\n",
    "print(\"Time taken to predict:\", time_taken_all_features_train, \"seconds\")\n",
    "print(\"Model Accuracy:\", accuracy_score(y_initial_train, y_initial_train_pred))\n",
    "print(classification_report(y_initial_train, y_initial_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a process object to track current process\n",
    "process = psutil.Process(os.getpid())\n",
    "# tracking start time\n",
    "start_time = time.time()\n",
    "# Make predictions on the test set\n",
    "y_initial_test_pred = clf_all_features.predict(X_initial_test)\n",
    "# tracking end time\n",
    "end_time = time.time()\n",
    "\n",
    "time_taken_all_features_test = end_time - start_time\n",
    "memory_used_all_features_test = process.memory_info().rss / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 1088.140625 MB\n",
      "Time taken to predict: 0.5216999053955078 seconds\n",
      "Model Accuracy: 0.6894827586206896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.84      0.71      1977\n",
      "           0       0.83      0.43      0.57        35\n",
      "           1       0.70      0.37      0.48        38\n",
      "           2       0.83      0.92      0.87        37\n",
      "           3       0.79      0.61      0.69        36\n",
      "           4       0.69      0.74      0.71        34\n",
      "           5       0.82      0.86      0.84        36\n",
      "           6       0.89      0.91      0.90        35\n",
      "           7       0.65      0.64      0.65        47\n",
      "           8       0.92      0.59      0.72        39\n",
      "           9       0.56      0.44      0.49        32\n",
      "          10       0.65      0.52      0.58        33\n",
      "          11       0.80      0.62      0.70        45\n",
      "          12       0.83      0.93      0.88        43\n",
      "          13       0.47      0.35      0.40        40\n",
      "          14       0.86      0.43      0.58        44\n",
      "          15       0.76      0.68      0.71        37\n",
      "          16       0.85      0.55      0.67        40\n",
      "          17       0.55      0.55      0.55        42\n",
      "          18       0.70      0.70      0.70        40\n",
      "          19       0.70      0.59      0.64        32\n",
      "          20       0.93      0.98      0.96        44\n",
      "          21       0.81      0.33      0.46        40\n",
      "          22       0.58      0.47      0.52        38\n",
      "          23       0.83      0.76      0.79        38\n",
      "          24       0.42      0.21      0.28        38\n",
      "          25       0.65      0.51      0.57        39\n",
      "          26       0.76      0.67      0.71        42\n",
      "          27       0.90      0.60      0.72        45\n",
      "          28       0.87      0.83      0.85        41\n",
      "          29       0.61      0.55      0.58        31\n",
      "          30       0.67      0.72      0.69        36\n",
      "          31       0.90      0.67      0.77        42\n",
      "          32       0.64      0.43      0.51        42\n",
      "          33       0.77      0.68      0.72        44\n",
      "          34       0.75      0.41      0.53        37\n",
      "          35       0.81      0.83      0.82        35\n",
      "          36       0.63      0.73      0.68        33\n",
      "          37       0.81      0.47      0.59        45\n",
      "          38       0.85      0.64      0.73        45\n",
      "          39       0.88      0.57      0.70        40\n",
      "          40       0.69      0.47      0.56        51\n",
      "          41       0.77      0.84      0.80        44\n",
      "          42       0.50      0.22      0.30        37\n",
      "          43       0.64      0.77      0.70        35\n",
      "          44       0.73      0.90      0.81        40\n",
      "          45       0.82      0.49      0.61        47\n",
      "          46       0.71      0.61      0.66        41\n",
      "          47       0.69      0.45      0.55        40\n",
      "          48       0.86      0.45      0.59        42\n",
      "          49       0.83      0.69      0.75        42\n",
      "          50       0.76      0.67      0.71        42\n",
      "          51       0.71      0.34      0.46        50\n",
      "          52       0.82      0.63      0.71        43\n",
      "          53       0.61      0.63      0.62        30\n",
      "          54       0.94      0.72      0.82        47\n",
      "          55       0.52      0.36      0.42        39\n",
      "          56       0.93      0.93      0.93        40\n",
      "          57       0.75      0.55      0.63        33\n",
      "          58       0.89      0.91      0.90        43\n",
      "          59       0.77      0.75      0.76        44\n",
      "          60       0.79      0.69      0.74        45\n",
      "          61       0.72      0.50      0.59        46\n",
      "          62       0.75      0.61      0.67        49\n",
      "          63       0.63      0.44      0.52        43\n",
      "          64       0.65      0.65      0.65        31\n",
      "          65       0.75      0.59      0.66        51\n",
      "          66       0.70      0.72      0.71        32\n",
      "          67       0.83      0.78      0.80        45\n",
      "          68       0.92      0.32      0.48        37\n",
      "          69       0.55      0.61      0.58        36\n",
      "          70       0.97      0.90      0.94        40\n",
      "          71       0.65      0.54      0.59        37\n",
      "          72       0.79      0.54      0.64        48\n",
      "          73       0.85      0.76      0.80        46\n",
      "          74       0.62      0.50      0.55        52\n",
      "          75       0.82      0.90      0.86        40\n",
      "          76       0.94      0.94      0.94        36\n",
      "          77       0.61      0.22      0.32        50\n",
      "          78       0.38      0.14      0.20        43\n",
      "          79       0.58      0.43      0.49        44\n",
      "          80       0.77      0.81      0.79        42\n",
      "          81       0.62      0.59      0.61        34\n",
      "          82       0.82      0.53      0.65        43\n",
      "          83       0.69      0.73      0.71        37\n",
      "          84       0.67      0.61      0.64        36\n",
      "          85       0.73      0.88      0.80        43\n",
      "          86       0.83      0.95      0.89        37\n",
      "          87       0.82      0.59      0.69        39\n",
      "          88       0.71      0.62      0.67        40\n",
      "          89       0.52      0.40      0.45        35\n",
      "          90       0.69      0.63      0.66        35\n",
      "          91       0.64      0.50      0.56        32\n",
      "          92       0.65      0.52      0.58        42\n",
      "          93       0.93      0.82      0.88        51\n",
      "          94       0.67      0.50      0.57        36\n",
      "\n",
      "    accuracy                           0.69      5800\n",
      "   macro avg       0.74      0.62      0.66      5800\n",
      "weighted avg       0.70      0.69      0.68      5800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy and other metrics\n",
    "print(\"Memory used:\", memory_used_all_features_test, \"MB\")\n",
    "print(\"Time taken to predict:\", time_taken_all_features_test, \"seconds\")\n",
    "print(\"Model Accuracy:\", accuracy_score(y_initial_test, y_initial_test_pred))\n",
    "print(classification_report(y_initial_test, y_initial_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.DataFrame(X_initial_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incoming_packet_counts</th>\n",
       "      <th>outgoing_packet_counts</th>\n",
       "      <th>total_packet_counts</th>\n",
       "      <th>incoming_packet_fraction</th>\n",
       "      <th>outgoing_packet_fraction</th>\n",
       "      <th>std_outgoing_order</th>\n",
       "      <th>avg_outgoing_order</th>\n",
       "      <th>sum_concentration</th>\n",
       "      <th>avg_concentration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9363</th>\n",
       "      <td>4257</td>\n",
       "      <td>439</td>\n",
       "      <td>4696</td>\n",
       "      <td>0.906516</td>\n",
       "      <td>0.093484</td>\n",
       "      <td>1605.353458</td>\n",
       "      <td>2166.134396</td>\n",
       "      <td>38.97</td>\n",
       "      <td>0.008299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23806</th>\n",
       "      <td>1640</td>\n",
       "      <td>132</td>\n",
       "      <td>1772</td>\n",
       "      <td>0.925508</td>\n",
       "      <td>0.074492</td>\n",
       "      <td>522.748381</td>\n",
       "      <td>713.037879</td>\n",
       "      <td>12.51</td>\n",
       "      <td>0.007060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5653</th>\n",
       "      <td>608</td>\n",
       "      <td>92</td>\n",
       "      <td>700</td>\n",
       "      <td>0.868571</td>\n",
       "      <td>0.131429</td>\n",
       "      <td>227.868929</td>\n",
       "      <td>325.532609</td>\n",
       "      <td>7.74</td>\n",
       "      <td>0.011057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16613</th>\n",
       "      <td>3778</td>\n",
       "      <td>321</td>\n",
       "      <td>4099</td>\n",
       "      <td>0.921688</td>\n",
       "      <td>0.078312</td>\n",
       "      <td>1398.928849</td>\n",
       "      <td>2426.224299</td>\n",
       "      <td>51.25</td>\n",
       "      <td>0.012503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10512</th>\n",
       "      <td>3286</td>\n",
       "      <td>462</td>\n",
       "      <td>3748</td>\n",
       "      <td>0.876734</td>\n",
       "      <td>0.123266</td>\n",
       "      <td>1205.709131</td>\n",
       "      <td>2265.525974</td>\n",
       "      <td>41.54</td>\n",
       "      <td>0.011083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       incoming_packet_counts  outgoing_packet_counts  total_packet_counts  \\\n",
       "9363                     4257                     439                 4696   \n",
       "23806                    1640                     132                 1772   \n",
       "5653                      608                      92                  700   \n",
       "16613                    3778                     321                 4099   \n",
       "10512                    3286                     462                 3748   \n",
       "\n",
       "       incoming_packet_fraction  outgoing_packet_fraction  std_outgoing_order  \\\n",
       "9363                   0.906516                  0.093484         1605.353458   \n",
       "23806                  0.925508                  0.074492          522.748381   \n",
       "5653                   0.868571                  0.131429          227.868929   \n",
       "16613                  0.921688                  0.078312         1398.928849   \n",
       "10512                  0.876734                  0.123266         1205.709131   \n",
       "\n",
       "       avg_outgoing_order  sum_concentration  avg_concentration  \n",
       "9363          2166.134396              38.97           0.008299  \n",
       "23806          713.037879              12.51           0.007060  \n",
       "5653           325.532609               7.74           0.011057  \n",
       "16613         2426.224299              51.25           0.012503  \n",
       "10512         2265.525974              41.54           0.011083  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using entropy\n",
    "model_1= RandomForestClassifier(n_estimators=100, criterion=\"entropy\", max_depth=100, min_samples_split=2, max_features=\"sqrt\", random_state=42)\n",
    "model_1.fit(X_initial_train, y_initial_train)\n",
    "feature_imp_1 = pd.Series(model_1.feature_importances_, index=df_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using gini\n",
    "model_2= RandomForestClassifier(n_estimators=100, criterion=\"gini\", max_depth=100, min_samples_split=2, max_features=\"sqrt\", random_state=42)\n",
    "model_2.fit(X_initial_train, y_initial_train)\n",
    "feature_imp_2 = pd.Series(model_2.feature_importances_, index=df_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_names = df_X.columns\n",
    "entropy_values = feature_imp_1.values\n",
    "gini_values = feature_imp_2.values\n",
    "\n",
    "bar_width = 0.4 \n",
    "y_positions = range(len(feature_names)) \n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "#plotting entropy importance\n",
    "plt.barh(\n",
    "    [y - bar_width / 2 for y in y_positions],\n",
    "    entropy_values,\n",
    "    bar_width,\n",
    "    label='Entropy',\n",
    "    color='blue',\n",
    ")\n",
    "\n",
    "# plotting gini improtance\n",
    "plt.barh(\n",
    "    [y + bar_width / 2 for y in y_positions],\n",
    "    gini_values,\n",
    "    bar_width,\n",
    "    label='Gini',\n",
    "    color='orange',\n",
    ")\n",
    "\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.yticks(y_positions, feature_names) \n",
    "plt.title('Visualisation of Feature Importance: Entropy vs Gini')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the extracted features:\n",
    "> **Feature Group 1: Traffic Volume (Absolute)**  \n",
    "> - Feature 1: Number of incoming packets  \n",
    "> - Feature 2: Number of outgoing packets  \n",
    "> - Feature 3: Total number of packets  \n",
    "> \n",
    "> **Feature Group 2: Traffic Volume (Fraction)**\n",
    "> - Feature 1: Number of incoming packets as a fraction of the total number of packets  \n",
    "> - Feature 2: Number of outgoing packets as a fraction of the total number of packets \n",
    "> \n",
    "> **Feature Group 3: Traffic Ordering List**\n",
    "> - Feature 6: Standard deviation of the outgoing packets ordering list  \n",
    "> - Feature 7: Average of the outgoing packets ordering list  \n",
    "> \n",
    "> **Feature Group 4: Traffic concentration** \n",
    "> - Feature 8: Sum of all items in the alternative concentration feature list  \n",
    "> - Feature 9: Average of all items in the alternative concentration feature list  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noted that within each of the 4 feature groups, the features are likely to be highly correlated due to their similarity. Furthermore, feature groups 1 and 2 are closely related as well with 1 being an absolute measurement of traffic volume and 2 as the ratio. Hence we will be selecting 2 features from the combination of group 1 and 2, and 1 feature each from group 3 and 4.\n",
    "\n",
    "According to our feature importance analysis, we have selected the features to be\n",
    "1. Feature 1: Number of incoming packets   \n",
    "2. Feature 3: Total number of packets\n",
    "3. Feature 7: Average of the outgoing packets ordering list \n",
    "4. Feature 8: Sum of all items in the alternative concentration feature list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = extracted_df[['incoming_packet_counts', 'total_packet_counts', 'avg_outgoing_order', 'sum_concentration']]\n",
    "y = extracted_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing Model with selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we construct an arbitrary random forest classification model using arbitrarily chosen parameters. This section aims to explore the implementation of the model. These parameters will be tuned in the next section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incoming_packet_counts</th>\n",
       "      <th>total_packet_counts</th>\n",
       "      <th>avg_outgoing_order</th>\n",
       "      <th>sum_concentration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9363</th>\n",
       "      <td>4257</td>\n",
       "      <td>4696</td>\n",
       "      <td>2166.134396</td>\n",
       "      <td>38.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23806</th>\n",
       "      <td>1640</td>\n",
       "      <td>1772</td>\n",
       "      <td>713.037879</td>\n",
       "      <td>12.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5653</th>\n",
       "      <td>608</td>\n",
       "      <td>700</td>\n",
       "      <td>325.532609</td>\n",
       "      <td>7.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16613</th>\n",
       "      <td>3778</td>\n",
       "      <td>4099</td>\n",
       "      <td>2426.224299</td>\n",
       "      <td>51.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10512</th>\n",
       "      <td>3286</td>\n",
       "      <td>3748</td>\n",
       "      <td>2265.525974</td>\n",
       "      <td>41.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       incoming_packet_counts  total_packet_counts  avg_outgoing_order  \\\n",
       "9363                     4257                 4696         2166.134396   \n",
       "23806                    1640                 1772          713.037879   \n",
       "5653                      608                  700          325.532609   \n",
       "16613                    3778                 4099         2426.224299   \n",
       "10512                    3286                 3748         2265.525974   \n",
       "\n",
       "       sum_concentration  \n",
       "9363               38.97  \n",
       "23806              12.51  \n",
       "5653                7.74  \n",
       "16613              51.25  \n",
       "10512              41.54  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=100, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=100, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=100, random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "clf_selected_features = RandomForestClassifier(n_estimators=100, criterion=\"entropy\", max_depth=100, min_samples_split=2, max_features=\"sqrt\", random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf_selected_features.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a process object to track current process\n",
    "process = psutil.Process(os.getpid())\n",
    "# tracking start time\n",
    "start_time = time.time()\n",
    "# Make predictions on the train set\n",
    "y_train_pred = clf_selected_features.predict(X_train)\n",
    "# tracking end time\n",
    "end_time = time.time()\n",
    "\n",
    "time_taken_selected_features_train = end_time - start_time\n",
    "memory_used_selected_features_train = process.memory_info().rss / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 4038.09375 MB\n",
      "Time taken to predict: 3.1234469413757324 seconds\n",
      "Model Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00      8023\n",
      "           0       1.00      1.00      1.00       165\n",
      "           1       1.00      1.00      1.00       162\n",
      "           2       1.00      1.00      1.00       163\n",
      "           3       1.00      1.00      1.00       164\n",
      "           4       1.00      1.00      1.00       166\n",
      "           5       1.00      1.00      1.00       164\n",
      "           6       1.00      1.00      1.00       165\n",
      "           7       1.00      1.00      1.00       153\n",
      "           8       1.00      1.00      1.00       161\n",
      "           9       1.00      1.00      1.00       168\n",
      "          10       1.00      1.00      1.00       167\n",
      "          11       1.00      1.00      1.00       155\n",
      "          12       1.00      1.00      1.00       157\n",
      "          13       1.00      1.00      1.00       160\n",
      "          14       1.00      1.00      1.00       156\n",
      "          15       1.00      1.00      1.00       163\n",
      "          16       1.00      1.00      1.00       160\n",
      "          17       1.00      1.00      1.00       158\n",
      "          18       1.00      1.00      1.00       160\n",
      "          19       1.00      1.00      1.00       168\n",
      "          20       1.00      1.00      1.00       156\n",
      "          21       1.00      1.00      1.00       160\n",
      "          22       1.00      1.00      1.00       162\n",
      "          23       1.00      1.00      1.00       162\n",
      "          24       1.00      1.00      1.00       162\n",
      "          25       1.00      1.00      1.00       161\n",
      "          26       1.00      1.00      1.00       158\n",
      "          27       1.00      1.00      1.00       155\n",
      "          28       1.00      1.00      1.00       159\n",
      "          29       1.00      1.00      1.00       169\n",
      "          30       1.00      1.00      1.00       164\n",
      "          31       1.00      1.00      1.00       158\n",
      "          32       1.00      1.00      1.00       158\n",
      "          33       1.00      1.00      1.00       156\n",
      "          34       1.00      1.00      1.00       163\n",
      "          35       1.00      1.00      1.00       165\n",
      "          36       1.00      1.00      1.00       167\n",
      "          37       1.00      1.00      1.00       155\n",
      "          38       1.00      1.00      1.00       155\n",
      "          39       1.00      1.00      1.00       160\n",
      "          40       1.00      1.00      1.00       149\n",
      "          41       1.00      1.00      1.00       156\n",
      "          42       1.00      1.00      1.00       163\n",
      "          43       1.00      1.00      1.00       165\n",
      "          44       1.00      1.00      1.00       160\n",
      "          45       1.00      1.00      1.00       153\n",
      "          46       1.00      1.00      1.00       159\n",
      "          47       1.00      1.00      1.00       160\n",
      "          48       1.00      1.00      1.00       158\n",
      "          49       1.00      1.00      1.00       158\n",
      "          50       1.00      1.00      1.00       158\n",
      "          51       1.00      1.00      1.00       150\n",
      "          52       1.00      1.00      1.00       157\n",
      "          53       1.00      1.00      1.00       170\n",
      "          54       1.00      1.00      1.00       153\n",
      "          55       1.00      1.00      1.00       161\n",
      "          56       1.00      1.00      1.00       160\n",
      "          57       1.00      1.00      1.00       167\n",
      "          58       1.00      1.00      1.00       157\n",
      "          59       1.00      1.00      1.00       156\n",
      "          60       1.00      1.00      1.00       155\n",
      "          61       1.00      1.00      1.00       154\n",
      "          62       1.00      1.00      1.00       151\n",
      "          63       1.00      1.00      1.00       157\n",
      "          64       1.00      1.00      1.00       169\n",
      "          65       1.00      1.00      1.00       149\n",
      "          66       1.00      1.00      1.00       168\n",
      "          67       1.00      1.00      1.00       155\n",
      "          68       1.00      1.00      1.00       163\n",
      "          69       1.00      1.00      1.00       164\n",
      "          70       1.00      1.00      1.00       160\n",
      "          71       1.00      1.00      1.00       163\n",
      "          72       1.00      1.00      1.00       152\n",
      "          73       1.00      1.00      1.00       154\n",
      "          74       1.00      1.00      1.00       148\n",
      "          75       1.00      1.00      1.00       160\n",
      "          76       1.00      1.00      1.00       164\n",
      "          77       1.00      1.00      1.00       150\n",
      "          78       1.00      1.00      1.00       157\n",
      "          79       1.00      1.00      1.00       156\n",
      "          80       1.00      1.00      1.00       158\n",
      "          81       1.00      1.00      1.00       166\n",
      "          82       1.00      1.00      1.00       157\n",
      "          83       1.00      1.00      1.00       163\n",
      "          84       1.00      1.00      1.00       164\n",
      "          85       1.00      1.00      1.00       157\n",
      "          86       1.00      1.00      1.00       163\n",
      "          87       1.00      1.00      1.00       161\n",
      "          88       1.00      1.00      1.00       160\n",
      "          89       1.00      1.00      1.00       165\n",
      "          90       1.00      1.00      1.00       165\n",
      "          91       1.00      1.00      1.00       168\n",
      "          92       1.00      1.00      1.00       158\n",
      "          93       1.00      1.00      1.00       149\n",
      "          94       1.00      1.00      1.00       164\n",
      "\n",
      "    accuracy                           1.00     23200\n",
      "   macro avg       1.00      1.00      1.00     23200\n",
      "weighted avg       1.00      1.00      1.00     23200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy and other metrics\n",
    "print(\"Memory used:\", memory_used_selected_features_train, \"MB\")\n",
    "print(\"Time taken to predict:\", time_taken_selected_features_train, \"seconds\")\n",
    "print(\"Model Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a process object to track current process\n",
    "process = psutil.Process(os.getpid())\n",
    "# tracking start time\n",
    "start_time = time.time()\n",
    "# Make predictions on the test set\n",
    "y_test_pred = clf_selected_features.predict(X_test)\n",
    "# tracking end time\n",
    "end_time = time.time()\n",
    "\n",
    "time_taken_selected_features_test = end_time - start_time\n",
    "memory_used_selected_features_test = process.memory_info().rss / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 4038.109375 MB\n",
      "Time taken to predict: 0.7140085697174072 seconds\n",
      "Model Accuracy: 0.6024137931034482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.58      0.80      0.67      1977\n",
      "           0       0.72      0.37      0.49        35\n",
      "           1       0.39      0.18      0.25        38\n",
      "           2       0.74      0.76      0.75        37\n",
      "           3       0.58      0.53      0.55        36\n",
      "           4       0.47      0.53      0.50        34\n",
      "           5       0.64      0.58      0.61        36\n",
      "           6       0.72      0.74      0.73        35\n",
      "           7       0.39      0.28      0.33        47\n",
      "           8       0.63      0.44      0.52        39\n",
      "           9       0.46      0.38      0.41        32\n",
      "          10       0.60      0.45      0.52        33\n",
      "          11       0.64      0.51      0.57        45\n",
      "          12       0.73      0.77      0.75        43\n",
      "          13       0.36      0.25      0.29        40\n",
      "          14       0.58      0.34      0.43        44\n",
      "          15       0.61      0.59      0.60        37\n",
      "          16       0.71      0.55      0.62        40\n",
      "          17       0.40      0.45      0.43        42\n",
      "          18       0.63      0.55      0.59        40\n",
      "          19       0.63      0.53      0.58        32\n",
      "          20       0.91      0.93      0.92        44\n",
      "          21       0.41      0.17      0.25        40\n",
      "          22       0.32      0.29      0.31        38\n",
      "          23       0.80      0.74      0.77        38\n",
      "          24       0.17      0.05      0.08        38\n",
      "          25       0.65      0.44      0.52        39\n",
      "          26       0.66      0.55      0.60        42\n",
      "          27       0.65      0.29      0.40        45\n",
      "          28       0.71      0.78      0.74        41\n",
      "          29       0.39      0.45      0.42        31\n",
      "          30       0.68      0.69      0.68        36\n",
      "          31       0.79      0.45      0.58        42\n",
      "          32       0.46      0.38      0.42        42\n",
      "          33       0.62      0.64      0.63        44\n",
      "          34       0.41      0.19      0.26        37\n",
      "          35       0.73      0.77      0.75        35\n",
      "          36       0.53      0.55      0.54        33\n",
      "          37       0.60      0.33      0.43        45\n",
      "          38       0.60      0.47      0.53        45\n",
      "          39       0.77      0.57      0.66        40\n",
      "          40       0.67      0.35      0.46        51\n",
      "          41       0.76      0.84      0.80        44\n",
      "          42       0.27      0.08      0.12        37\n",
      "          43       0.58      0.71      0.64        35\n",
      "          44       0.82      0.82      0.82        40\n",
      "          45       0.65      0.32      0.43        47\n",
      "          46       0.68      0.41      0.52        41\n",
      "          47       0.52      0.30      0.38        40\n",
      "          48       0.76      0.38      0.51        42\n",
      "          49       0.82      0.67      0.74        42\n",
      "          50       0.56      0.55      0.55        42\n",
      "          51       0.58      0.30      0.39        50\n",
      "          52       0.79      0.63      0.70        43\n",
      "          53       0.39      0.50      0.44        30\n",
      "          54       0.67      0.51      0.58        47\n",
      "          55       0.43      0.26      0.32        39\n",
      "          56       0.85      0.85      0.85        40\n",
      "          57       0.46      0.39      0.43        33\n",
      "          58       0.76      0.91      0.83        43\n",
      "          59       0.70      0.68      0.69        44\n",
      "          60       0.60      0.47      0.53        45\n",
      "          61       0.53      0.37      0.44        46\n",
      "          62       0.59      0.39      0.47        49\n",
      "          63       0.47      0.35      0.40        43\n",
      "          64       0.62      0.68      0.65        31\n",
      "          65       0.58      0.49      0.53        51\n",
      "          66       0.60      0.66      0.63        32\n",
      "          67       0.72      0.64      0.68        45\n",
      "          68       0.42      0.14      0.20        37\n",
      "          69       0.34      0.39      0.36        36\n",
      "          70       0.95      0.88      0.91        40\n",
      "          71       0.55      0.49      0.51        37\n",
      "          72       0.59      0.40      0.47        48\n",
      "          73       0.86      0.65      0.74        46\n",
      "          74       0.46      0.31      0.37        52\n",
      "          75       0.84      0.93      0.88        40\n",
      "          76       0.92      0.94      0.93        36\n",
      "          77       0.45      0.10      0.16        50\n",
      "          78       0.08      0.02      0.04        43\n",
      "          79       0.59      0.36      0.45        44\n",
      "          80       0.74      0.74      0.74        42\n",
      "          81       0.49      0.50      0.49        34\n",
      "          82       0.57      0.47      0.51        43\n",
      "          83       0.63      0.65      0.64        37\n",
      "          84       0.48      0.42      0.45        36\n",
      "          85       0.69      0.84      0.76        43\n",
      "          86       0.94      0.84      0.89        37\n",
      "          87       0.58      0.64      0.61        39\n",
      "          88       0.62      0.40      0.48        40\n",
      "          89       0.37      0.37      0.37        35\n",
      "          90       0.54      0.43      0.48        35\n",
      "          91       0.62      0.56      0.59        32\n",
      "          92       0.57      0.31      0.40        42\n",
      "          93       0.89      0.82      0.86        51\n",
      "          94       0.55      0.33      0.41        36\n",
      "\n",
      "    accuracy                           0.60      5800\n",
      "   macro avg       0.60      0.51      0.54      5800\n",
      "weighted avg       0.60      0.60      0.58      5800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy and other metrics\n",
    "print(\"Memory used:\", memory_used_selected_features_test, \"MB\")\n",
    "print(\"Time taken to predict:\", time_taken_selected_features_test, \"seconds\")\n",
    "print(\"Model Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the parameter grid for the Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [10, 15],\n",
    "    'min_samples_leaf': [5, 10],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True],\n",
    "    'criterion': ['gini', 'entropy']           \n",
    "}\n",
    "\n",
    "# Defining the grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5,  \n",
    "    refit=True, \n",
    "    verbose = 3,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    }
   ],
   "source": [
    "# Fitting the grid search\n",
    "start_time = time.time()\n",
    "grid.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "time_taken_grid_search = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for grid search: 2487.351676464081 seconds\n"
     ]
    }
   ],
   "source": [
    "# Print the time taken to perform the grid search\n",
    "print(\"Time taken for grid search:\", time_taken_grid_search, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Print best parameters after grid search\n",
    "print(\"Best parameters found:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a process object to track current process\n",
    "process = psutil.Process(os.getpid())\n",
    "# tracking start time\n",
    "start_time = time.time()\n",
    "# Make predictions on the test set\n",
    "y_train_pred = grid.predict(X_train)\n",
    "# tracking end time\n",
    "end_time = time.time()\n",
    "\n",
    "time_taken_selected_features_tuned_train = end_time - start_time\n",
    "memory_used_selected_features_tuned_train = process.memory_info().rss / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 738.1953125 MB\n",
      "Time taken to predict: 2.1690099239349365 seconds\n",
      "Model Accuracy: 0.7570258620689655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.66      0.95      0.78      8023\n",
      "           0       0.96      0.60      0.74       165\n",
      "           1       0.97      0.46      0.62       162\n",
      "           2       0.86      0.82      0.84       163\n",
      "           3       0.92      0.75      0.83       164\n",
      "           4       0.87      0.67      0.76       166\n",
      "           5       0.85      0.77      0.81       164\n",
      "           6       0.97      0.77      0.86       165\n",
      "           7       0.82      0.71      0.76       153\n",
      "           8       0.89      0.75      0.81       161\n",
      "           9       0.88      0.64      0.74       168\n",
      "          10       0.82      0.54      0.65       167\n",
      "          11       0.87      0.60      0.71       155\n",
      "          12       0.86      0.88      0.87       157\n",
      "          13       0.87      0.47      0.62       160\n",
      "          14       0.90      0.41      0.56       156\n",
      "          15       0.83      0.76      0.79       163\n",
      "          16       0.87      0.64      0.74       160\n",
      "          17       0.81      0.50      0.62       158\n",
      "          18       0.78      0.71      0.74       160\n",
      "          19       0.87      0.65      0.75       168\n",
      "          20       0.86      0.94      0.90       156\n",
      "          21       0.89      0.44      0.59       160\n",
      "          22       0.83      0.51      0.63       162\n",
      "          23       0.86      0.69      0.76       162\n",
      "          24       0.86      0.26      0.40       162\n",
      "          25       0.86      0.65      0.74       161\n",
      "          26       0.87      0.82      0.84       158\n",
      "          27       0.90      0.60      0.72       155\n",
      "          28       0.90      0.65      0.76       159\n",
      "          29       0.75      0.69      0.72       169\n",
      "          30       0.80      0.76      0.78       164\n",
      "          31       0.94      0.65      0.77       158\n",
      "          32       0.86      0.62      0.72       158\n",
      "          33       0.83      0.74      0.78       156\n",
      "          34       0.81      0.40      0.53       163\n",
      "          35       0.83      0.82      0.83       165\n",
      "          36       0.84      0.77      0.80       167\n",
      "          37       0.84      0.33      0.47       155\n",
      "          38       0.84      0.65      0.73       155\n",
      "          39       0.95      0.71      0.81       160\n",
      "          40       0.89      0.44      0.59       149\n",
      "          41       0.90      0.84      0.87       156\n",
      "          42       0.88      0.39      0.54       163\n",
      "          43       0.86      0.85      0.86       165\n",
      "          44       0.90      0.88      0.89       160\n",
      "          45       0.75      0.40      0.52       153\n",
      "          46       0.92      0.53      0.67       159\n",
      "          47       0.81      0.57      0.67       160\n",
      "          48       0.91      0.66      0.76       158\n",
      "          49       0.91      0.82      0.86       158\n",
      "          50       0.74      0.78      0.76       158\n",
      "          51       0.88      0.45      0.59       150\n",
      "          52       0.88      0.56      0.68       157\n",
      "          53       0.74      0.52      0.61       170\n",
      "          54       0.89      0.77      0.83       153\n",
      "          55       0.89      0.39      0.54       161\n",
      "          56       0.95      0.91      0.93       160\n",
      "          57       0.86      0.59      0.70       167\n",
      "          58       0.79      0.89      0.84       157\n",
      "          59       0.80      0.74      0.77       156\n",
      "          60       0.87      0.64      0.74       155\n",
      "          61       0.81      0.64      0.72       154\n",
      "          62       0.85      0.69      0.76       151\n",
      "          63       0.90      0.50      0.64       157\n",
      "          64       0.89      0.66      0.76       169\n",
      "          65       0.75      0.63      0.69       149\n",
      "          66       0.86      0.80      0.83       168\n",
      "          67       0.87      0.71      0.78       155\n",
      "          68       0.85      0.41      0.55       163\n",
      "          69       0.77      0.60      0.67       164\n",
      "          70       0.94      0.92      0.93       160\n",
      "          71       0.79      0.63      0.70       163\n",
      "          72       0.81      0.62      0.70       152\n",
      "          73       0.90      0.80      0.85       154\n",
      "          74       0.71      0.64      0.68       148\n",
      "          75       0.89      0.91      0.90       160\n",
      "          76       0.94      0.91      0.93       164\n",
      "          77       0.97      0.19      0.32       150\n",
      "          78       0.89      0.36      0.51       157\n",
      "          79       0.87      0.56      0.68       156\n",
      "          80       0.91      0.87      0.89       158\n",
      "          81       0.90      0.63      0.74       166\n",
      "          82       0.92      0.52      0.66       157\n",
      "          83       0.77      0.85      0.81       163\n",
      "          84       0.80      0.67      0.73       164\n",
      "          85       0.81      0.85      0.83       157\n",
      "          86       0.95      0.91      0.93       163\n",
      "          87       0.79      0.74      0.76       161\n",
      "          88       0.89      0.60      0.72       160\n",
      "          89       0.78      0.47      0.59       165\n",
      "          90       0.71      0.70      0.70       165\n",
      "          91       0.83      0.70      0.76       168\n",
      "          92       0.91      0.53      0.67       158\n",
      "          93       0.90      0.91      0.90       149\n",
      "          94       0.92      0.49      0.64       164\n",
      "\n",
      "    accuracy                           0.76     23200\n",
      "   macro avg       0.86      0.66      0.73     23200\n",
      "weighted avg       0.79      0.76      0.75     23200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy and other metrics\n",
    "print(\"Memory used:\", memory_used_selected_features_tuned_train, \"MB\")\n",
    "print(\"Time taken to predict:\", time_taken_selected_features_tuned_train, \"seconds\")\n",
    "print(\"Model Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a process object to track current process\n",
    "process = psutil.Process(os.getpid())\n",
    "# tracking start time\n",
    "start_time = time.time()\n",
    "# Make predictions on the test set\n",
    "y_test_pred = grid.predict(X_test)\n",
    "# tracking end time\n",
    "end_time = time.time()\n",
    "\n",
    "time_taken_selected_features_tuned_test = end_time - start_time\n",
    "memory_used_selected_features_tuned_test = process.memory_info().rss / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory used: 739.765625 MB\n",
      "Time taken to predict: 0.7559921741485596 seconds\n",
      "Model Accuracy: 0.5793103448275863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.52      0.86      0.65      1977\n",
      "           0       0.83      0.29      0.43        35\n",
      "           1       0.33      0.05      0.09        38\n",
      "           2       0.72      0.70      0.71        37\n",
      "           3       0.64      0.44      0.52        36\n",
      "           4       0.64      0.41      0.50        34\n",
      "           5       0.73      0.53      0.61        36\n",
      "           6       0.85      0.63      0.72        35\n",
      "           7       0.43      0.26      0.32        47\n",
      "           8       0.68      0.44      0.53        39\n",
      "           9       0.48      0.31      0.38        32\n",
      "          10       0.53      0.30      0.38        33\n",
      "          11       0.64      0.40      0.49        45\n",
      "          12       0.67      0.72      0.70        43\n",
      "          13       0.47      0.17      0.25        40\n",
      "          14       0.67      0.18      0.29        44\n",
      "          15       0.73      0.59      0.66        37\n",
      "          16       0.80      0.50      0.62        40\n",
      "          17       0.38      0.33      0.35        42\n",
      "          18       0.64      0.53      0.58        40\n",
      "          19       0.68      0.47      0.56        32\n",
      "          20       0.87      0.93      0.90        44\n",
      "          21       0.56      0.12      0.20        40\n",
      "          22       0.38      0.16      0.22        38\n",
      "          23       0.76      0.66      0.70        38\n",
      "          24       0.00      0.00      0.00        38\n",
      "          25       0.62      0.41      0.49        39\n",
      "          26       0.56      0.48      0.51        42\n",
      "          27       0.67      0.22      0.33        45\n",
      "          28       0.76      0.68      0.72        41\n",
      "          29       0.33      0.39      0.36        31\n",
      "          30       0.56      0.67      0.61        36\n",
      "          31       0.90      0.43      0.58        42\n",
      "          32       0.42      0.19      0.26        42\n",
      "          33       0.69      0.55      0.61        44\n",
      "          34       0.64      0.19      0.29        37\n",
      "          35       0.71      0.69      0.70        35\n",
      "          36       0.57      0.52      0.54        33\n",
      "          37       0.58      0.16      0.25        45\n",
      "          38       0.71      0.33      0.45        45\n",
      "          39       0.87      0.50      0.63        40\n",
      "          40       0.67      0.20      0.30        51\n",
      "          41       0.77      0.77      0.77        44\n",
      "          42       0.50      0.05      0.10        37\n",
      "          43       0.56      0.63      0.59        35\n",
      "          44       0.91      0.78      0.84        40\n",
      "          45       0.87      0.28      0.42        47\n",
      "          46       0.80      0.29      0.43        41\n",
      "          47       0.56      0.25      0.34        40\n",
      "          48       0.69      0.26      0.38        42\n",
      "          49       0.93      0.67      0.78        42\n",
      "          50       0.48      0.48      0.48        42\n",
      "          51       0.41      0.14      0.21        50\n",
      "          52       0.77      0.47      0.58        43\n",
      "          53       0.52      0.37      0.43        30\n",
      "          54       0.75      0.51      0.61        47\n",
      "          55       0.57      0.10      0.17        39\n",
      "          56       0.83      0.85      0.84        40\n",
      "          57       0.41      0.27      0.33        33\n",
      "          58       0.74      0.81      0.78        43\n",
      "          59       0.63      0.59      0.61        44\n",
      "          60       0.57      0.36      0.44        45\n",
      "          61       0.52      0.33      0.40        46\n",
      "          62       0.59      0.27      0.37        49\n",
      "          63       0.44      0.28      0.34        43\n",
      "          64       0.67      0.58      0.62        31\n",
      "          65       0.59      0.47      0.52        51\n",
      "          66       0.71      0.69      0.70        32\n",
      "          67       0.69      0.56      0.62        45\n",
      "          68       0.50      0.11      0.18        37\n",
      "          69       0.41      0.33      0.37        36\n",
      "          70       0.95      0.90      0.92        40\n",
      "          71       0.63      0.46      0.53        37\n",
      "          72       0.50      0.31      0.38        48\n",
      "          73       0.91      0.63      0.74        46\n",
      "          74       0.45      0.37      0.40        52\n",
      "          75       0.79      0.85      0.82        40\n",
      "          76       0.92      0.94      0.93        36\n",
      "          77       1.00      0.06      0.11        50\n",
      "          78       0.22      0.05      0.08        43\n",
      "          79       0.53      0.36      0.43        44\n",
      "          80       0.81      0.81      0.81        42\n",
      "          81       0.54      0.44      0.48        34\n",
      "          82       0.78      0.42      0.55        43\n",
      "          83       0.49      0.57      0.53        37\n",
      "          84       0.44      0.42      0.43        36\n",
      "          85       0.57      0.81      0.67        43\n",
      "          86       0.94      0.81      0.87        37\n",
      "          87       0.55      0.56      0.56        39\n",
      "          88       0.68      0.33      0.44        40\n",
      "          89       0.36      0.23      0.28        35\n",
      "          90       0.52      0.37      0.43        35\n",
      "          91       0.50      0.47      0.48        32\n",
      "          92       0.69      0.21      0.33        42\n",
      "          93       0.87      0.78      0.82        51\n",
      "          94       0.50      0.22      0.31        36\n",
      "\n",
      "    accuracy                           0.58      5800\n",
      "   macro avg       0.63      0.44      0.50      5800\n",
      "weighted avg       0.60      0.58      0.55      5800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy and other metrics\n",
    "print(\"Memory used:\", memory_used_selected_features_tuned_test, \"MB\")\n",
    "print(\"Time taken to predict:\", time_taken_selected_features_tuned_test, \"seconds\")\n",
    "print(\"Model Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/ow_multi.pkl', 'wb') as f:\n",
    "    pickle.dump(classification_report(y_test, y_test_pred, output_dict=True), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
